
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1.6. Die Jordansche Normalform &#8212; Mathematik für Data Science 2</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e2363ea40746bee74734a24ffefccd78.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "C": "\\mathbb{C}", "K": "\\mathbb{K}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "R": ["\\mathbb{R}"], "norm": ["{\\Vert#1\\Vert}", 1], "abs": ["{|#1|}", 1], "coloneqq": ["{:=}"], "eqqcolon": ["{=:}"], "emph": ["\\pmb#1", 1], "tr": "\\operatorname{Spur}", "lin": "\\operatorname{lin}", "dv": "\\mathrm{div}~", "rot": "\\mathrm{rot}~", "Dim": "\\operatorname{dim}", "diag": "\\operatorname{diag}", "Kern": "\\operatorname{Kern}", "Bild": "\\operatorname{Bild}", "Rang": "\\operatorname{Rang}", "GL": "\\operatorname{GL}", "Eig": "\\operatorname{Eig}", "End": "\\operatorname{End}", "Hau": "\\operatorname{Haupt}", "mymathbb": ["\\boldsymbol{#1}", 1], "idx": "\\mathrm{d}x"}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/cropped-fau_solo_aufblau_192x192_rgb-180x180.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Euklidische und unitäre Vektorräume" href="../vektoraeume/vektoraeume.html" />
    <link rel="prev" title="1.5. Trigonalisierbarkeit" href="triag.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/FAU-DMM-Logo-rgb-10cm.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Mathematik für Data Science 2</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Mathematik für DataScience 2
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Lineare Algebra
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="eigenwerte.html">
   1. Eigenwerte
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="prelim.html">
     1.1. Mathematische Grundlagen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="werte_vektoren.html">
     1.2. Eigenwerte und Eigenvektoren
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="char_pol.html">
     1.3. Das charakteristische Polynom
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="diag.html">
     1.4. Diagonalisierbarkeit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="triag.html">
     1.5. Trigonalisierbarkeit
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     1.6. Die Jordansche Normalform
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../vektoraeume/vektoraeume.html">
   2. Euklidische und unitäre Vektorräume
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../vektoraeume/standard_skalar.html">
     2.1. Das kanonische Skalarprodukt in
     <span class="math notranslate nohighlight">
      \(\mathbb{R}^n\)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vektoraeume/vektor_produkt.html">
     2.2. Das Vektorprodukt in
     <span class="math notranslate nohighlight">
      \(\mathbb{R}^3\)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vektoraeume/complex_skalar.html">
     2.3. Das kanonische Skalarprodukt in
     <span class="math notranslate nohighlight">
      \(\mathbb{C}^n\)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vektoraeume/sesqui.html">
     2.4. Bilinear- und Sesquilinearformen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vektoraeume/orth.html">
     2.5. Orthogonalisierung und Orthonormalisierung
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vektoraeume/orth_endo.html">
     2.6. Orthogonale und unitäre Endomorphismen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vektoraeume/selbstadjungiert.html">
     2.7. Selbstadjungierte Endomorphismen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vektoraeume/normal.html">
     2.8. Normale Endomorphismen
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Analysis
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../normierte_raeume/normierte_raeume.html">
   3. Normierte Vektorräume
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../normierte_raeume/konvergenz.html">
     3.1. Konvergenz von Folgen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normierte_raeume/stetigkeit.html">
     3.2. Stetigkeit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normierte_raeume/kompaktheit.html">
     3.3. Kompaktheit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normierte_raeume/hilbert.html">
     3.4. Hilberträume
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../normierte_raeume/dual.html">
     3.5. Dualräume
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../integrale/integrale.html">
   4. Integralrechnung
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrale/part_int.html">
     4.1. Partielle Integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrale/substitution.html">
     4.2. Substitutionsregel
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../integrale/rat_func.html">
     4.3. Integration rationaler Funktionen
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ableitungen/ableitungen.html">
   5. Differentiation von Funktionen mehrerer Veränderlicher
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ableitungen/part_diff.html">
     5.1. Partielle Differenzierbarkeit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ableitungen/first_order.html">
     5.2. Differentialoperatoren erster Ordnung
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ableitungen/higher_order.html">
     5.3. Differentialoperatoren höherer Ordnung
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ableitungen/tot_diff.html">
     5.4. Totale Differenzierbarkeit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ableitungen/taylor.html">
     5.5. Taylor-Formel
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../optimierung/optimierung.html">
   6. Optimierung
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../optimierung/unrestringiert.html">
     6.1. Unrestringierte Optimierung
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../optimierung/nebenbedingungen.html">
     6.2. Optimierung unter Nebenbedingungen
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ode/ode.html">
   7. Gewöhnliche Differentialgleichungen
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/tdv.html">
     7.1. Trennung der Variablen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ode/vdk.html">
     7.2. Variation der Konstanten
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Anhang
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../references.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/eigenwerte/jordan.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nilpotente-matrizen">
   1.6.1. Nilpotente Matrizen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hauptraum-und-hauptvektoren">
   1.6.2. Hauptraum und Hauptvektoren
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hauptraumzerlegung">
   1.6.3. Hauptraumzerlegung
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalisierung-nilpotenter-endomorphismen">
   1.6.4. Normalisierung nilpotenter Endomorphismen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#jordansche-normalform">
   1.6.5. Jordansche Normalform
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="die-jordansche-normalform">
<h1><span class="section-number">1.6. </span>Die Jordansche Normalform<a class="headerlink" href="#die-jordansche-normalform" title="Permalink to this headline">¶</a></h1>
<p>An einer Triagonalmatrix können wir bereits Rang und Eigenwerte ablesen, jedoch keine weiteren charakteristischen Eigenschaften des zu Grunde liegenden Endomorphismus, wie z.B. die Dimension der Eigenräume.
Außerdem kann die obere, rechte Dreiecksmatrix voll besetzt in der oberen Hälfte sein, so dass sie für numerische Verfahren eher ungünstig ist.
Das wirkt sich vor allem bei der Potenzierung von Endomorphismen in iterativen Verfahren aus, bei der diese Mehrfachanwendung zu unerwünschten Rechenoperationen führt.
Ein weiteres Problem ist, das allgemeine Triagonalmatrizen ungeeignet sind um explizite Lösungen von Systemen linearer Differentialgleichungen anzugeben, da die Gleichungen nicht hinreichend entkoppeln in dieser Darstellung.</p>
<p>Es ist also ganz natürlich sich die Frage zu stellen, ob für eine gegebene trigonalisierbare Matrix <span class="math notranslate nohighlight">\(A\)</span> eine kanonische Wahl einer oberen, rechten Dreiecksmatrix existiert, die einfach und interpretierbar aufgebaut ist und nur wenige Wahlmöglichkeiten bei der Bestimmung zulässt.
Die Frage, wie durch geschickte Wahl einer Basis <span class="math notranslate nohighlight">\(B\)</span> von des endlich-dimensionalen Vektorraums <span class="math notranslate nohighlight">\(V\)</span> die darstellende Matrix <span class="math notranslate nohighlight">\(M_B(F)\)</span> des Endomorphismus <span class="math notranslate nohighlight">\(F\)</span> auf eine möglichst einfache und eindeutige Gestalt gebracht werden kann, ist allerdings deutlich schwieriger als die bereits bekannte Triagonalisierung einer Matrix.
Diese Frage wird zentral in der Normalformentheorie von Endomorphismen behandelt.</p>
<p>Wie wir im Folgenden sehen werden existiert glücklicherweise eine kanonische Darstellung einer trigonalisierbaren Matrix, welche <em>Jordansche Normalform</em> genannt wird, und die die gewünschten Eigenschaften hat.</p>
<p>Bevor wir uns jedoch mit dem Studium dieser Normalform beschäftigen führen die Definition eines nilpotenten Endomorphismus ein.</p>
<div class="proof definition admonition" id="definition-0">
<p class="admonition-title"><span class="caption-number">Definition 1.12 </span> (Nilpotenz)</p>
<div class="definition-content section" id="proof-content">
<p>Wir definieren den Begriff der <em>Nilpotenz</em> im folgenden sowohl für Endomorphismen als auch für Matrizen.</p>
<ol class="simple">
<li><p>Ein Endormorphismus <span class="math notranslate nohighlight">\(F \colon V \rightarrow V\)</span> eines <span class="math notranslate nohighlight">\(\mathbb{K}\)</span>-Vektorraums <span class="math notranslate nohighlight">\(V\)</span> heißt <em>nilpotent</em>, falls es einen Index <span class="math notranslate nohighlight">\(k\in \mathbb{N}\)</span> gibt, so dass <span class="math notranslate nohighlight">\(F^k =\!\!\!\!\!\!\underbrace{F \circ \ldots \circ F}_{k\text{-fache Anwendung}} \!\!\!\!\!\!= 0\)</span> ist.
Der kleinste solche Index <span class="math notranslate nohighlight">\(k\)</span> heißt dann <em>Nilpotenzindex</em>.</p></li>
<li><p>Eine Matrix <span class="math notranslate nohighlight">\(A \in \mathbb{K}^{n \times n}\)</span> heißt <em>nilpotent</em>, falls es einen Index <span class="math notranslate nohighlight">\(k\in \mathbb{N}\)</span> gibt, so dass <span class="math notranslate nohighlight">\(A^k =\!\!\!\!\!\!\underbrace{A \cdot \ldots \cdot A}_{k\text{-fache Anwendung}} \!\!\!\!\!\!= 0\)</span> ist.
Der kleinste solche Index <span class="math notranslate nohighlight">\(k\)</span> heißt dann <em>Nilpotenzindex</em>.</p></li>
</ol>
</div>
</div><div class="proof example admonition" id="bsp:nilpotenz">
<p class="admonition-title"><span class="caption-number">Example 1.7 </span></p>
<div class="example-content section" id="proof-content">
<p>Wir wollen im Folgenden den Nilpotenzindex zweier Matrizen durch ihre Potenzierung bestimmen.</p>
<ul class="simple">
<li><p>Wir betrachten die Matrix <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{3 \times 3}\)</span>  mit</p></li>
</ul>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A \ \coloneqq \ 
\begin{pmatrix}
5 &amp; -3 &amp; 2\\
15 &amp; -9 &amp; 6\\
10 &amp; -6 &amp; 4
\end{pmatrix}.
\end{equation*}\]</div>
<p>Wir betrachten Potenzen von <span class="math notranslate nohighlight">\(A\)</span> und erhalten:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A^2 \ = \ 
\begin{pmatrix}
0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0
\end{pmatrix}.
\end{equation*}\]</div>
<p>Erstaunlicherweise ist der Nilpotenzindex der Matrix <span class="math notranslate nohighlight">\(A\)</span> schon <span class="math notranslate nohighlight">\(k = 2\)</span>.
\item Wir betrachten die Matrix <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{4 \times 4}\)</span>  mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A \ = \ 
\begin{pmatrix}
0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}.
\end{equation*}\]</div>
<p>Wir betrachten Potenzen von <span class="math notranslate nohighlight">\(A\)</span> und erhalten:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A^2 \ = \ 
\begin{pmatrix}
0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix},  \quad
A^3 \ = \ 
\begin{pmatrix}
0 &amp; 0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}, \quad
 A^4 \ = \ 
\begin{pmatrix}
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0
\end{pmatrix}.
\end{equation*}\]</div>
<p>Der Nilpotenzindex der Matrix <span class="math notranslate nohighlight">\(A\)</span> ist also <span class="math notranslate nohighlight">\(k = 4\)</span>.</p>
</div>
</div><div class="section" id="nilpotente-matrizen">
<h2><span class="section-number">1.6.1. </span>Nilpotente Matrizen<a class="headerlink" href="#nilpotente-matrizen" title="Permalink to this headline">¶</a></h2>
<p>Die Matrix <span class="math notranslate nohighlight">\(A\)</span> aus dem zweiten Beispiel <a class="reference internal" href="#bsp:nilpotenz">Example 1.7</a> ist in einer besonderen Form, welche wir näher betrachten werden.</p>
<div class="proof definition admonition" id="def:normalform_nilpotent">
<p class="admonition-title"><span class="caption-number">Definition 1.13 </span> (Normalform für nilpotente Matrizen)</p>
<div class="definition-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(k \in \mathbb{N}, k \geq 1\)</span>, dann definieren wir eine <em>nilpotente Matrix in Normalform</em> <span class="math notranslate nohighlight">\(N_k \in \mathbb{K}^{k\times k}\)</span> durch:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
(N_k)_{i,j} \ \coloneqq \ \delta_{i,j-1} \ = \ \begin{cases}1, \quad \text{ falls } i=j-1,\\ 0, \quad \text{ sonst }.  \end{cases}
\end{equation*}\]</div>
<p>Hierbei bezeichnet <span class="math notranslate nohighlight">\(\delta_{i,j}\)</span> das Kronecker-Delta.
Das heißt <span class="math notranslate nohighlight">\(N_k\)</span> ist eine Matrix, die nur auf der oberen, ersten Nebendiagonale Einsen besitzt und deren sonstige Einträge alle Null sind.
Diese Normalform von nilpotenten Matrizen wird auch \emph{Jordanmatrix} genannt.</p>
</div>
</div><p>Wir wollen im Folgenden einige nützliche Eigenschaften von nilpotenten Matrizen angeben.</p>
<div class="proof lemma admonition" id="lem:dreieck_nilpotent">
<p class="admonition-title"><span class="caption-number">Lemma 1.6 </span></p>
<div class="lemma-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(A \in \mathbb{K}^{n \times n}\)</span> eine strikte obere, rechte Dreiecksmatrix, d.h., für die Diagonalelemente gilt <span class="math notranslate nohighlight">\(a_{ii} = 0, 1 \leq i \leq n\)</span>. Dann ist <span class="math notranslate nohighlight">\(A\)</span> nilpotent ist und besitzt einen Nilpotenzindex von <span class="math notranslate nohighlight">\(k\leq n\)</span>.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Wir beweisen die Behauptung per vollständige Induktion über die Dimension <span class="math notranslate nohighlight">\( n \)</span> von <span class="math notranslate nohighlight">\( A \)</span>:</p>
<p><strong>Induktionsanfang <span class="math notranslate nohighlight">\( n = 1 \)</span>:</strong></p>
<p>Falls <span class="math notranslate nohighlight">\( n= 1 \)</span>, so <span class="math notranslate nohighlight">\( A = (0) \)</span> und <span class="math notranslate nohighlight">\( A \)</span> ist offensichtlich nilpotent mit Index <span class="math notranslate nohighlight">\( 1 \leq n \)</span>.</p>
<p><strong>Induktionsschritt <span class="math notranslate nohighlight">\( n-1 \rightarrow n \)</span>, <span class="math notranslate nohighlight">\( n &gt; 1  \)</span>:</strong></p>
<p>Wenn <span class="math notranslate nohighlight">\( A \in \mathbb{K}^{n\times n } \)</span> eine strikte obere Dreiecksmatrix ist, dann gibt es eine strikte obere Dreiecksmatrix <span class="math notranslate nohighlight">\( A' \in \mathbb{K}^{(n-1)\times(n-1)} \)</span>, so dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A = \begin{pmatrix}
    &amp; \star \\
        A' &amp; \vdots \\
        &amp; \star \\
        0_{n-1} &amp; 0
    \end{pmatrix}.
\end{equation*}\]</div>
<p>Hierbei kennzeichnet <span class="math notranslate nohighlight">\( \star \)</span> einen Eintrag, welcher nicht notwendigerweise Null ist.
Wir sehen, dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    A^2 =
    \begin{pmatrix}
        (A')^2 &amp; A'(\star,\dots,\star)^T \\
        0_{n-1} &amp; 0
    \end{pmatrix}.
\end{equation*}\]</div>
<p>Per Induktionsvoraussetzung ist <span class="math notranslate nohighlight">\( A' \)</span> nilpotent mit Nilpotenzindex <span class="math notranslate nohighlight">\( \ell \leq n-1 \)</span>.
Wir rechnen nun</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    A^\ell =
    \begin{pmatrix}
        (A')^\ell &amp; (A')^{\ell-1}(\star,\dots,\star)^T \\
        0_{n-1} &amp; 0
    \end{pmatrix}
    =
    \begin{pmatrix}
        \mathbf{0}_{(n-1)\times(n-1)} &amp; (A')^{\ell-1}(\star,\dots,\star)^T \\
        0_{n-1} &amp; 0
    \end{pmatrix}.
\end{equation*}\]</div>
<p>Eine weitere Multiplikation mit <span class="math notranslate nohighlight">\( A \)</span> von links zeigt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    A
    \begin{pmatrix}
        \mathbf{0}_{(n-1)\times(n-1)} &amp; (A')^{\ell-1}(\star,\dots,\star)^T \\
        0_{n-1} &amp; 0
    \end{pmatrix}
    =
    \begin{pmatrix}
        \mathbf{0}_{(n-1)\times(n-1)} &amp; (A')^{\ell}(\star,\dots,\star)^T \\
        0_{n-1} &amp; 0
    \end{pmatrix}
    =
    \mathbf{0}_{n\times n}
\end{equation*}\]</div>
<p>und der Nilpotenzindex von <span class="math notranslate nohighlight">\( A \)</span> ist höchstens <span class="math notranslate nohighlight">\( \ell+1 \leq n \)</span>.</p>
</div>
<p>Wir wollen im folgenden Satz Kriterien herleiten, die aussagen wann eine obere, rechte Dreiecksmatrix nilpotent ist.</p>
<div class="proof theorem admonition" id="satz:nilpotent_eigenschaften">
<p class="admonition-title"><span class="caption-number">Theorem 1.8 </span></p>
<div class="theorem-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(A \in \mathbb{K}^{n\times n}\)</span> eine obere, rechte Dreiecksmatrix. Dann gelten die folgenden Aussagen:</p>
<p>i) <span class="math notranslate nohighlight">\(A\)</span> ist genau dann nilpotent, wenn alle Diagonalelemente <span class="math notranslate nohighlight">\(a_{ii}, 1\leq i\leq n\)</span>, gleich <span class="math notranslate nohighlight">\(0\)</span> sind.</p>
<p>ii) <span class="math notranslate nohighlight">\(A\)</span> ist genau dann nilpotent und diagonalisierbar, wenn <span class="math notranslate nohighlight">\(A\)</span> die Nullmatrix <span class="math notranslate nohighlight">\(\mymathbb{0} \in \mathbb{K}^{n \times n}\)</span> ist.</p>
<p>iii) Ist <span class="math notranslate nohighlight">\(A\)</span> nilpotent, so hat <span class="math notranslate nohighlight">\(A\)</span> nur den Eigenwert <span class="math notranslate nohighlight">\(0\)</span>.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. <strong>ad i)</strong> Man kann leicht zeigen, dass für eine obere, rechte Dreiecksmatrix <span class="math notranslate nohighlight">\(A\)</span> stets gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A^j \ = \
\begin{pmatrix}
a_{11}^j &amp;  &amp; *\\
 &amp; \ddots &amp; \\
 0 &amp; &amp; a_{nn}^j
\end{pmatrix}.
\end{equation*}\]</div>
<p>Damit <span class="math notranslate nohighlight">\(A\)</span> nilpotent ist, muss also für alle Diagonalelemente <span class="math notranslate nohighlight">\(a_{ii} = 0, 1 \leq i \leq n\)</span>, gelten.</p>
<p>Sei umgekehrt <span class="math notranslate nohighlight">\(A\)</span> eine obere, rechte Dreiecksmatrix deren Diagonalelemente <span class="math notranslate nohighlight">\(a_{ii} = 0\)</span> sind für <span class="math notranslate nohighlight">\(1 \leq i \leq n\)</span>. Dann folgt die Behauptung direkt mit Lemma <a class="reference internal" href="#lem:dreieck_nilpotent">Lemma 1.6</a>.</p>
<p><strong>ad ii)</strong> Falls <span class="math notranslate nohighlight">\(A = 0\)</span> die Nullmatrix ist, so ist <span class="math notranslate nohighlight">\(A\)</span> nilpotent vom Index <span class="math notranslate nohighlight">\(1\)</span> und trivialerweise diagonalisierbar.</p>
<p>Sei umgekehrt <span class="math notranslate nohighlight">\(A\)</span> nilpotent und diagonalisierbar, dann existiert eine reguläre Matrix <span class="math notranslate nohighlight">\(S \in \GL(n; \mathbb{K})\)</span>, so dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
S \cdot A \cdot S^{-1} \ = \
\begin{pmatrix}
\lambda_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \lambda_n
\end{pmatrix} \ \eqqcolon \ D,
\end{equation*}\]</div>
<p>wobei <span class="math notranslate nohighlight">\(\lambda_i, 1 \leq i \leq n\)</span>, die Eigenwerte von <span class="math notranslate nohighlight">\(A\)</span> sind.
Sei <span class="math notranslate nohighlight">\(k\)</span> der Nilpotenzindex von <span class="math notranslate nohighlight">\(A\)</span>.
Wie man leicht einsieht gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
D^k \ = \ (S \cdot A \cdot S^{-1})^k \ = \ S \cdot A^k \cdot S^{-1} \ = \
\begin{pmatrix}
\lambda_1^k &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \lambda_n^k
\end{pmatrix}.
\end{equation*}\]</div>
<p>Da <span class="math notranslate nohighlight">\(A^k = 0\)</span> die Nullmatrix ist, folgt schon, dass <span class="math notranslate nohighlight">\(\lambda_i = 0, 1 \leq i \leq n\)</span>, gelten muss.
Darum ist auch</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A \ = \ S^{-1} \cdot D \cdot S \ = \ 0.
\end{equation*}\]</div>
<p><strong>ad iii)</strong> Wir führen einen Beweis über Widerspruch. Nehmen wir an, dass die Behauptung nicht gelte, dann existiert ein Eigenwert <span class="math notranslate nohighlight">\(\lambda \neq 0\)</span> und ein zugehörigen Eigenvektor <span class="math notranslate nohighlight">\(v \neq \vec{0}\)</span>, so dass <span class="math notranslate nohighlight">\(Av = \lambda v\)</span>.</p>
<p>Da <span class="math notranslate nohighlight">\(A\)</span> nilpotent ist, existiert ein Index <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span>, so dass <span class="math notranslate nohighlight">\(A^{k-1} \neq 0\)</span>, jedoch <span class="math notranslate nohighlight">\(A^k = 0\)</span> gilt.
Aus der Eigenwertgleichung können wir folgern, dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
0 \ = \ A^kv \ = \ A^{k-1} \lambda v \ = \ \lambda^k v.
\end{equation*}\]</div>
<p>Daraus folgt aber, dass <span class="math notranslate nohighlight">\(\lambda = 0\)</span> oder <span class="math notranslate nohighlight">\(v = 0\)</span> gilt, was zum Widerspruch führt.</p>
</div>
<p>Der folgende Satz sagt uns, dass wir für jeden nilpotenten Endomorphismus eine darstellende Matrix finden können, die eine strikte obere, rechte Dreiecksgestalt besitzt.</p>
<div class="proof theorem admonition" id="satz:nilpotenz">
<p class="admonition-title"><span class="caption-number">Theorem 1.9 </span></p>
<div class="theorem-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(V\)</span> ein endlich-dimensionaler <span class="math notranslate nohighlight">\(\mathbb{K}\)</span>-Vektorraum und <span class="math notranslate nohighlight">\(F \colon V \rightarrow V\)</span> ein nilpotenter Endomorphismus von <span class="math notranslate nohighlight">\(V\)</span>.
Dann existiert eine Basis <span class="math notranslate nohighlight">\(B\)</span> von <span class="math notranslate nohighlight">\(V\)</span>, so dass die darstellende Matrix <span class="math notranslate nohighlight">\(M_B(F)\)</span> von <span class="math notranslate nohighlight">\(F\)</span> bezüglich <span class="math notranslate nohighlight">\(B\)</span> eine obere, rechte Dreiecksmatrix mit Nullen auf der Hauptdiagonale ist, d.h.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
M_B(F) \ = \
\begin{pmatrix}
0 &amp; &amp; * \\
   &amp; \ddots &amp; \\
0 &amp; &amp; 0
\end{pmatrix}
\end{equation*}\]</div>
<p>und es gilt <span class="math notranslate nohighlight">\(P_F(t) = (-1)^n t^n\)</span>.</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Wir führen den Beweis durch Induktion über <span class="math notranslate nohighlight">\(n = \dim V\)</span>.</p>
<p><strong>Induktionsanfang: <span class="math notranslate nohighlight">\(n=1\)</span></strong></p>
<p>Die Aussage ist trivialerweise erfüllt, da für einen nilpotenten Endomorphismus <span class="math notranslate nohighlight">\(F\)</span> eines eindimensionalen Vektorraums <span class="math notranslate nohighlight">\(V\)</span> gelten muss <span class="math notranslate nohighlight">\(F \equiv 0\)</span>.
Dadurch ist die darstellende Matrix für eine beliebige Basis <span class="math notranslate nohighlight">\(B\)</span> von <span class="math notranslate nohighlight">\(V\)</span> gegeben durch <span class="math notranslate nohighlight">\(M_B(F) = 0\)</span> und das charakteristische Polynom ist dementsprechend <span class="math notranslate nohighlight">\(P_F(t) = 0-t = (-1)^1 \cdot t^1\)</span>.</p>
<p><strong>Induktionsschritt: <span class="math notranslate nohighlight">\(n-1 \rightarrow n\)</span></strong></p>
<p>Die Induktionsannahme ist, dass die Aussage bereits für den Fall <span class="math notranslate nohighlight">\(n-1\)</span> gezeigt wurde.
Sei <span class="math notranslate nohighlight">\(F\)</span> nun ein nilpotenter Endomorphismus von <span class="math notranslate nohighlight">\(V\)</span> mit <span class="math notranslate nohighlight">\(F \not \equiv 0\)</span> (da ansonsten die Situation vom Induktionsanfang vorliegt).
Da nach Satz <a class="reference internal" href="#satz:nilpotent_eigenschaften">Theorem 1.8</a> Null der einzige Eigenwert von <span class="math notranslate nohighlight">\(F\)</span> ist wissen wir, dass <span class="math notranslate nohighlight">\(\dim \Bild(F(V)) &lt; \dim V\)</span> gilt und somit muss schon gelten, dass der Kern von <span class="math notranslate nohighlight">\(F\)</span> nicht-trivial ist, d.h., <span class="math notranslate nohighlight">\(\Kern F \neq \vec{0}\)</span>.</p>
<p>Sei nun <span class="math notranslate nohighlight">\(v_1 \in \Kern(F), v \neq \vec{0}\)</span>. Wir ergänzen <span class="math notranslate nohighlight">\(v_1\)</span> zu einer Basis <span class="math notranslate nohighlight">\(B' = (v_1, w_2, \ldots, w_n)\)</span> von <span class="math notranslate nohighlight">\(V\)</span>.
Mit Hilfe des Algorithmus <a class="reference internal" href="triag.html#alg:trigonalisierung">Algorithm 1.1</a> zur Trigonalisierung einer Matrix erhalten wir also:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
M_{B'}(F) \ = \
\begin{pmatrix}
0 &amp; a_{12} &amp; \dots &amp; a_{1n} \\
\vdots &amp; &amp; \\
\vdots &amp; &amp; B &amp; \\
0 &amp; &amp; &amp;
\end{pmatrix}
\end{equation*}\]</div>
<p>Da <span class="math notranslate nohighlight">\(W \coloneqq \lin(\lbrace w_2, \ldots, w_n \rbrace)\)</span> im Allgemeinen nicht <span class="math notranslate nohighlight">\(F\)</span>-invariant ist, definieren wir die linearen Abbildungen</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
H(w_j) \ = \ a_{1j} v_1 \quad \text{ und } \quad G(w_j) \ = \ a_{2j}w_2 + \ldots + a_{nj}w_n.
\end{equation*}\]</div>
<p>Dann können wir den Endomorphismus <span class="math notranslate nohighlight">\(F\)</span> schreiben als: <span class="math notranslate nohighlight">\(F(w) = H(w) + G(w)\)</span> für alle <span class="math notranslate nohighlight">\(w \in W\)</span>.
Bezüglich der Basis <span class="math notranslate nohighlight">\(\tilde{B}' = (w_2, \ldots, w_n)\)</span> gilt dann <span class="math notranslate nohighlight">\(B = M_{\tilde{B}'}(G)\)</span>.
Außerdem gilt, dass <span class="math notranslate nohighlight">\(\operatorname{Bild}(H) \subset \Kern(F)\)</span> und <span class="math notranslate nohighlight">\(G\)</span> ist nilpotent, da auf Grund der Nilpotenz von <span class="math notranslate nohighlight">\(F\)</span> für alle <span class="math notranslate nohighlight">\(w \in W\)</span> gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\begin{split}
0 \ = \ F^k(w) \ &amp;= \ F^{k-1}(F(w)) \\
&amp;= \ F^{k-1}(H(w) + G(w)) \ = \ F^{k-1}(\lambda v_1 + G(w)) \\
&amp;= \ F^{k-1}(G(w)) \ = \ \dots \ = \ F^{k-2}(G^2(w)) \ = \ \ldots \ = \ G^k(w).
\end{split}
\end{equation*}\]</div>
<p>Da <span class="math notranslate nohighlight">\(\dim W = \dim V - 1\)</span> gilt, können wir auf <span class="math notranslate nohighlight">\(G\)</span> die Induktionsvoraussetzung anwenden, d.h., es gibt eine Basis <span class="math notranslate nohighlight">\(\tilde{B} = (v_2, \ldots, v_n)\)</span> von <span class="math notranslate nohighlight">\(W\)</span>, so dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
M_{\tilde{B}}(G) \ = \
\begin{pmatrix}
0 &amp; &amp; * \\
   &amp; \ddots &amp; \\
0 &amp; &amp; 0
\end{pmatrix}
\end{equation*}\]</div>
<p>Damit folgt schon für die Basis <span class="math notranslate nohighlight">\(B = (v_1, \ldots, v_n)\)</span> von <span class="math notranslate nohighlight">\(V\)</span>, dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
M_B(F) \ = \
\begin{pmatrix}
0 &amp; &amp; * \\
   &amp; \ddots &amp; \\
0 &amp; &amp; 0
\end{pmatrix}
\end{equation*}\]</div>
<p>und das charakteristische Polynom ist dementsprechend <span class="math notranslate nohighlight">\(P_F(t) \ = \ (-1)^nt^n\)</span>.</p>
</div>
<p>Man kann sogar noch mehr zeigen als die Aussage der vorangegangenen Sätze und Lemmata, nämlich eine vollständige Charakterisierung von nilpotenten Endomorphismen, wie der folgende Satz zeigt.</p>
<div class="proof theorem admonition" id="satz:nilpotent_charakterisierung">
<p class="admonition-title"><span class="caption-number">Theorem 1.10 </span></p>
<div class="theorem-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(F \colon V \rightarrow V\)</span> ein Endomorphismus von <span class="math notranslate nohighlight">\(V\)</span>. Dann sind folgende Aussagen äquivalent:</p>
<p>i) <span class="math notranslate nohighlight">\(F\)</span> ist nilpotent.
ii) <span class="math notranslate nohighlight">\(F^k = 0\)</span> für ein <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span>.
iii) Das charakterstische Polynom <span class="math notranslate nohighlight">\(P_F\)</span> von <span class="math notranslate nohighlight">\(F\)</span> hat die Form <span class="math notranslate nohighlight">\(P_F(t) = (-1)^n t^n\)</span>.
iv) Es gibt eine Basis <span class="math notranslate nohighlight">\(B\)</span> von <span class="math notranslate nohighlight">\(V\)</span>, so dass die darstellende Matrix <span class="math notranslate nohighlight">\(M_B(F)\)</span> von <span class="math notranslate nohighlight">\(F\)</span> die folgende Gestalt hat:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
M_B(F) \ = \
\begin{pmatrix}
0 &amp; &amp; * \\
   &amp; \ddots &amp; \\
0 &amp; &amp; 0
\end{pmatrix}
\end{equation*}\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Siehe Satz 4.5.7 <span id="id1">[<a class="reference internal" href="../references.html#id3">Fis05</a>]</span>.</p>
</div>
<div class="proof remark admonition" id="remark-7">
<p class="admonition-title"><span class="caption-number">Remark 1.4 </span></p>
<div class="remark-content section" id="proof-content">
<p>Nilpotente Endomorphismen bzw. Matrizen besitzen nur den Eigenwert <span class="math notranslate nohighlight">\(\lambda = 0\)</span>, daher haben ihre darstellenden Matrizen keinen vollen Rang. Andersherum gibt es jedoch quadratische Matrizen, die nicht vollen Rang haben, jedoch nicht nilpotent sind, z.B. die Matrix</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
A \ \coloneqq \
\begin{pmatrix}
1 &amp; 1\\
0 &amp; 0
\end{pmatrix}
\end{equation*}\]</div>
<p>mit <span class="math notranslate nohighlight">\(A^k = A\)</span> für alle <span class="math notranslate nohighlight">\(k \in \mathbb{K}\)</span> und den Eigenwerten <span class="math notranslate nohighlight">\(\lambda_1 = 0\)</span> und <span class="math notranslate nohighlight">\(\lambda_2 = 1\)</span> von <span class="math notranslate nohighlight">\(A\)</span>.</p>
</div>
</div></div>
<div class="section" id="hauptraum-und-hauptvektoren">
<h2><span class="section-number">1.6.2. </span>Hauptraum und Hauptvektoren<a class="headerlink" href="#hauptraum-und-hauptvektoren" title="Permalink to this headline">¶</a></h2>
<p>Eine wichtige Erkenntnis zur Konstruktion der Jordanschen Normalform ist, dass der Kern des Endomorphismus <span class="math notranslate nohighlight">\(G \coloneqq (F - \lambda \operatorname{Id}_V)\)</span> mit jeder Potenz von <span class="math notranslate nohighlight">\(G\)</span> größer werden kann, wie folgendes Lemma zeigt.</p>
<div class="proof lemma admonition" id="lem:einbettung_kern">
<p class="admonition-title"><span class="caption-number">Lemma 1.7 </span></p>
<div class="lemma-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(F \colon V \rightarrow V\)</span> ein Endomorphismus des endlich-dimensionalen <span class="math notranslate nohighlight">\(\mathbb{K}\)</span>-Vektorraums <span class="math notranslate nohighlight">\(V\)</span> mit Eigenwert <span class="math notranslate nohighlight">\(\lambda \in \mathbb{K}\)</span>. Dann gilt für alle <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Kern(F - \lambda \operatorname{Id}_V) \ \subset \ \Kern([F - \lambda \operatorname{Id}_V]^k).
\end{equation*}\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Sei <span class="math notranslate nohighlight">\(G \coloneqq (F - \lambda \operatorname{Id}_V)\)</span>. Wir müssen zeigen, dass für beliebiges <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span> gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
v \in \Kern(G) \ \Rightarrow \ v \in \Kern(G^k), \quad \text{ für alle } v\in V.
\end{equation*}\]</div>
<p>Sei also <span class="math notranslate nohighlight">\(v \in \Kern(G)\)</span>, dann gilt offensichtlich <span class="math notranslate nohighlight">\(G v = 0\)</span>. Sei nun <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span> eine beliebige Potenz, dann betrachten wir</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
G^k v \ = \ G^{k-1} \underbrace{G v}_{= 0} \ = \ 0.
\end{equation*}\]</div>
<p>Daraus folgt also schon, dass <span class="math notranslate nohighlight">\(v \in \Kern(G^k)\)</span> gilt.</p>
</div>
<p>Nach Satz <a class="reference internal" href="diag.html#satz:diagonalisierbarkeit">Theorem 1.6</a> wissen wir, dass sich der Vektorraum <span class="math notranslate nohighlight">\(V\)</span> genau dann in eine direkte Summe von <span class="math notranslate nohighlight">\(F\)</span>-invarianten Eigenräumen <span class="math notranslate nohighlight">\(\Eig(F; \lambda_i), i=1,\ldots,k,\)</span> zerlegen lässt, wenn die Dimension jedes Eigenraums der algebraischen Vielfachheit <span class="math notranslate nohighlight">\(r_i \in \mathbb{N}\)</span> der Nullstellen des charakteristischen Polynoms entspricht, d.h.,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\dim \Eig(F; \lambda_i) \ = \ r_i, ¸\quad \text{ für } i=1,\ldots,k.
\end{equation*}\]</div>
<p>Falls die Dimension eines Eigenraums <span class="math notranslate nohighlight">\(\Eig(F; \lambda_i)\)</span> jedoch zu klein ist, so lässt sie sich durch Potenzieren mit <span class="math notranslate nohighlight">\(r_i\)</span> passend vergrößern, denn nach <a class="reference internal" href="#lem:einbettung_kern">Lemma 1.7</a> gilt:</p>
<div class="math notranslate nohighlight" id="equation-eq-eigenraum-potenz">
<span class="eqno">(1.13)<a class="headerlink" href="#equation-eq-eigenraum-potenz" title="Permalink to this equation">¶</a></span>\[\Eig(F; \lambda_i) \ = \ \Kern(F - \lambda_i \operatorname{Id}_V) \ \subset \ \Kern([F - \lambda_i \operatorname{Id}_V]^{r_i}).\]</div>
<p>Die Einbettung in <a class="reference internal" href="#equation-eq-eigenraum-potenz">(1.13)</a> motiviert folgende Definition des Hauptraums.</p>
<div class="proof definition admonition" id="definition-9">
<p class="admonition-title"><span class="caption-number">Definition 1.14 </span> (Hauptraum und Hauptvektoren)</p>
<div class="definition-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(F \colon V \rightarrow V\)</span> ein Endomorphismus des <span class="math notranslate nohighlight">\(\mathbb{K}\)</span>-Vektorraums <span class="math notranslate nohighlight">\(V\)</span>.
Sei außerdem <span class="math notranslate nohighlight">\(\lambda \in \mathbb{K}\)</span> ein Eigenwert von <span class="math notranslate nohighlight">\(F\)</span> der algebraischen Vielfachheit <span class="math notranslate nohighlight">\(r \geq 1\)</span>.
Dann definieren wir den \emph{Hauptraum} oder \emph{verallgemeinerten Eigenraum} <span class="math notranslate nohighlight">\(\Hau(F; \lambda)\)</span> von <span class="math notranslate nohighlight">\(F\)</span> zum Eigenwert <span class="math notranslate nohighlight">\(\lambda\)</span> als Kern der <span class="math notranslate nohighlight">\(r\)</span>-fachen Anwendung von <span class="math notranslate nohighlight">\((F - \lambda \operatorname{Id}_V)\)</span>, d.h.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Hau(F; \lambda) \ \coloneqq \ \Kern([F - \lambda \operatorname{Id}_V]^r).
\end{equation*}\]</div>
<p>Die Vektoren <span class="math notranslate nohighlight">\(v \in \Hau(F; \lambda)\)</span> werden \emph{Hauptvektoren} der Stufe <span class="math notranslate nohighlight">\(d \geq 1\)</span> genannt, wenn gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
[F - \lambda \operatorname{Id}_V]^d (v) \ = \ 0, \quad [F - \lambda \operatorname{Id}_V]^{d-1} (v) \ \neq \ 0.
\end{equation*}\]</div>
<p>Damit ergibt sich, dass alle Eigenvektoren Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(d=1\)</span> sind.</p>
</div>
</div><p>Um zu verstehen, wie sich die Potenzierung der Endomorphismen auswirkt betrachten wir einen Eigenwert <span class="math notranslate nohighlight">\(\lambda \in \mathbb{K}\)</span> des Endomorphismus <span class="math notranslate nohighlight">\(F \colon V \rightarrow V\)</span> und Potenzen des Endomorphimus <span class="math notranslate nohighlight">\(G \coloneqq F - \lambda \operatorname{Id}_V\)</span>.
Wir stellen fest, dass wir folgende Inklusionsketten erhalten:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\lbrace{\vec{0}\rbrace} &amp;\subset \Kern G \subset \Kern G^2 \subset \ldots \subset \Kern G^l ,\\
V &amp;\supset \Bild G \supset \Bild G^2 \supset \ldots \supset \Bild G^l.
\end{align*}\]</div>
<p>Außerdem gilt nach dem Dimensionssatz (Satz 2.2.4 <span id="id2">[<a class="reference internal" href="../references.html#id3">Fis05</a>]</span>), dass <span class="math notranslate nohighlight">\(\dim \Kern G^l + \dim \Bild G^l = \dim V\)</span> ist.
Jedoch sind die Mengen im Allgemeinen nicht disjunkt wie bei einer direkten Summe, d.h., wir haben nicht</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Kern G^l \cap \Bild G^l \ \neq \ \lbrace{\vec{0}\rbrace}.
\end{equation*}\]</div>
<p>Da <span class="math notranslate nohighlight">\(V\)</span> jedoch endlich-dimensional ist, können die beiden obigen Inklusionsketten nicht beliebig auf- bzw. absteigen.</p>
<p>Das folgende nützliche Lemma charakterisiert die Eigenschaften dieser Inklusionsketten noch genauer.</p>
<div class="proof lemma admonition" id="lem:fitting">
<p class="admonition-title"><span class="caption-number">Lemma 1.8 </span> (Lemma von Fitting)</p>
<div class="lemma-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(G \colon V \rightarrow V\)</span> ein Endomorphismus des <span class="math notranslate nohighlight">\(\mathbb{K}\)</span>-Vektorraums <span class="math notranslate nohighlight">\(V\)</span>.
Sei außerdem <span class="math notranslate nohighlight">\(\lambda = 0\)</span> ein Eigenwert von <span class="math notranslate nohighlight">\(G\)</span> mit algebraischer Vielfachheit <span class="math notranslate nohighlight">\(r \in \mathbb{N}, r \geq 1\)</span>.
Wir betrachten die kleinste Potenz <span class="math notranslate nohighlight">\(d \in \mathbb{N}\)</span> für die der Kern von <span class="math notranslate nohighlight">\(G\)</span> sich nicht mehr ändert, d.h.,</p>
<div class="math notranslate nohighlight" id="equation-eq-fitting-index">
<span class="eqno">(1.14)<a class="headerlink" href="#equation-eq-fitting-index" title="Permalink to this equation">¶</a></span>\[d \ \coloneqq \ \min\lbrace{l \in \mathbb{N} \: | \: \Kern(G^l) \, = \, \Kern(G^{l+1}) \rbrace},\]</div>
<p>wobei <span class="math notranslate nohighlight">\(G^0 \coloneqq \operatorname{Id}_V\)</span> gilt.
Dann gelten die folgenden Aussagen:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(d \, = \, \min \lbrace{l \in \mathbb{N} \: | \: \Bild(G^l) \, = \, \Bild(G^{l+1}) \rbrace}\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(\Kern(G^{d+i}) = \Kern(G^{d}), \quad \Bild(G^{d+i}) = \Bild(G^{d})\)</span> \quad für alle <span class="math notranslate nohighlight">\(i \in \mathbb{N}\)</span>,</p></li>
<li><p>Die Räume <span class="math notranslate nohighlight">\(U \coloneqq \Kern(G^d)\)</span> und <span class="math notranslate nohighlight">\(W \coloneqq \Bild(G^d)\)</span> sind <span class="math notranslate nohighlight">\(G\)</span>-invariant,</p></li>
<li><p><span class="math notranslate nohighlight">\((G|_{U})^d \ = \ 0\)</span> \ und \ <span class="math notranslate nohighlight">\(G|_{W} \colon W \rightarrow W\)</span> ist ein Isomorphismus,</p></li>
<li><p><span class="math notranslate nohighlight">\(V \ = \ U \oplus W\)</span>.</p></li>
</ol>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Wir nehmen an <span class="math notranslate nohighlight">\(d \in \mathbb{N}\)</span> sei der kleinste Index mit der Eigenschaft aus \eqref{eq:fitting_index}.
Dann können wir mit der Dimensionsformel \cite[Satz 2.2.4]{fischer} folgern, dass gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\begin{split}
\Kern(G^{d+1}) \, = \, \Kern(G^{d}) \ &amp;\Leftrightarrow \ \dim(\Kern(G^{d+1})) \, = \, \dim(\Kern(G^{d})) \\
&amp;\Leftrightarrow \ \dim(\Bild(G^{d+1})) \, = \, \dim(\Bild(G^{d})) \\
&amp;\Leftrightarrow \ \Bild(G^{d+1}) \, = \, \Bild(G^{d}).
\end{split}
\end{equation*}\]</div>
<p>Das bedeutet schon, dass die Abbildung <span class="math notranslate nohighlight">\(G|_W\)</span> für <span class="math notranslate nohighlight">\(W \coloneqq \Bild(G^d)\)</span> mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
G|_W \colon W \rightarrow \Bild(G^{d+1}) = W
\end{equation*}\]</div>
<p>ein Isomorphismus ist.
Aus dieser Beobachtung folgen schon die ersten drei Aussagen, sowie der zweite Teil der vierten Aussage.
Die Nilpotenz der Abbildung <span class="math notranslate nohighlight">\(G|_U\)</span> mit Nilpotenzindex <span class="math notranslate nohighlight">\(d\)</span> ist auch klar, da für alle <span class="math notranslate nohighlight">\(v \in U = \Kern(G^k)\)</span> gilt, dass <span class="math notranslate nohighlight">\(G^d (v) = 0\)</span>  ist.</p>
<p>Sei nun <span class="math notranslate nohighlight">\(v \in U \cap W\)</span>, dann ist <span class="math notranslate nohighlight">\(G^d(v) = 0\)</span> und es muss ein <span class="math notranslate nohighlight">\(w \in V\)</span> geben, so dass <span class="math notranslate nohighlight">\(G^d(w) = v\)</span> ist.
Setzen wir die erste Beobachtung in die zweite Beobachtung ein erhalten wir, dass auch <span class="math notranslate nohighlight">\(G^{2d}(w) = 0\)</span> sein muss und somit gilt nach der zweiten Aussage des Lemmas, dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
w \in \Kern(G^{2d}) = \Kern(G^{d}).
\end{equation*}\]</div>
<p>Damit folgt aber schon, dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
0 \ = \ G^d(w) \ = \ v,
\end{equation*}\]</div>
<p>und somit gilt <span class="math notranslate nohighlight">\(V = U \oplus W\)</span>.</p>
</div>
</div>
<div class="section" id="hauptraumzerlegung">
<h2><span class="section-number">1.6.3. </span>Hauptraumzerlegung<a class="headerlink" href="#hauptraumzerlegung" title="Permalink to this headline">¶</a></h2>
<p>Durch die Betrachtung von Haupträumen anstatt Eigenräumen lässt sich eine mögliche Differenz zwischen algebraischen und geometrischen Vielfachheiten der Eigenwerte eines Endomorphismus ausgleichen.
Wie wir im folgenden Satz sehen werden lässt sich der Vektorraum <span class="math notranslate nohighlight">\(V\)</span> nun in eine innere direkte Summe der Haupträume zerlegen.
Dies war bisher nur für diagonalisierbare Endomorphismen mit Hilfe der Eigenräume in Satz <a class="reference internal" href="diag.html#satz:diagonalisierbarkeit">Theorem 1.6</a> möglich und bringt uns einen großen Schritt in Richtung der Jordanschen Normalform voran.</p>
<div class="proof theorem admonition" id="satz:hauptraumzerlegung">
<p class="admonition-title"><span class="caption-number">Theorem 1.11 </span> (Hauptraumzerlegung)</p>
<div class="theorem-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(F \colon V \rightarrow V\)</span> ein Endomorphismus des <span class="math notranslate nohighlight">\(\mathbb{K}\)</span>-Vektorraums <span class="math notranslate nohighlight">\(V\)</span> und sei</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P_F(t) \ = \ \pm (t - \lambda_1)^{r_1} \cdot \ldots \cdot (t  - \lambda_k)^{r_k}
\end{equation*}\]</div>
<p>das charakteristische Polynom von <span class="math notranslate nohighlight">\(F\)</span> mit paarweisen verschiedenen <span class="math notranslate nohighlight">\(\lambda_1, \ldots, \lambda_k \in \mathbb{K}\)</span>, die die Eigenwerte von <span class="math notranslate nohighlight">\(F\)</span> darstellen und deren algebraischen Vielfachheiten <span class="math notranslate nohighlight">\(r_i \in \mathbb{N}, r_i \geq 1\)</span> sind.
Es sei außerdem <span class="math notranslate nohighlight">\(V_i \coloneqq \Hau(F; \lambda_i) \subset V\)</span> für jedes <span class="math notranslate nohighlight">\(\lambda_i\)</span> der entsprechende Hauptraum.
Dann gelten die folgenden Aussagen:
\begin{enumerate}
\item <span class="math notranslate nohighlight">\(V \ = \ V_1 \, \oplus \ldots \oplus \, V_k\)</span>
\item <span class="math notranslate nohighlight">\(F(V_i) \subset V_i\)</span> und <span class="math notranslate nohighlight">\(\dim V_i = r_i\)</span> für <span class="math notranslate nohighlight">\(i = 1,\ldots,k\)</span>
\item <span class="math notranslate nohighlight">\(F\)</span> hat eine Zerlegung <span class="math notranslate nohighlight">\(F = F_D + F_N\)</span> mit:
\begin{enumerate}[a)]
\item <span class="math notranslate nohighlight">\(F_D\)</span> ist diagonalisierbar
\item <span class="math notranslate nohighlight">\(F_N\)</span> ist nilpotent
\item <span class="math notranslate nohighlight">\(F_N\)</span> und <span class="math notranslate nohighlight">\(F_D\)</span> kommutieren, d.h., <span class="math notranslate nohighlight">\(F_D \circ F_N = F_N \circ F_D\)</span>
\end{enumerate}
\end{enumerate}</p>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Wir führen den Beweis mittels vollständiger Induktion über die Zahl <span class="math notranslate nohighlight">\(k \geq 1\)</span> der paarweise verschiedenen Eigenwerte von <span class="math notranslate nohighlight">\(F\)</span>.
~\[0.3cm]
\textbf{Induktionsanfang: <span class="math notranslate nohighlight">\(k=1\)</span>}\
Für <span class="math notranslate nohighlight">\(k=1\)</span> existiert nur ein Eigenwert <span class="math notranslate nohighlight">\(\lambda \in \mathbb{K}\)</span> von <span class="math notranslate nohighlight">\(F\)</span>.
Das bedeutet, dass das charakteristische Polynom <span class="math notranslate nohighlight">\(P_F\)</span> von der Form ist</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P_F(t) \ = \ \pm (t - \lambda)^n
\end{equation*}\]</div>
<p>und somit hat <span class="math notranslate nohighlight">\(\lambda\)</span> die algebraische Vielfachheit <span class="math notranslate nohighlight">\(n = \dim(V)\)</span>.
Damit gilt für <span class="math notranslate nohighlight">\(V_1 = \Hau(F; \lambda)\)</span> schon</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
V_1 \ = \ \Kern([F - \lambda \operatorname{Id}_V]^n) \ = \ V,
\end{equation*}\]</div>
<p>da <span class="math notranslate nohighlight">\(F - \lambda \operatorname{Id}_V\)</span> nilpotent ist mit Nilpotenzindex <span class="math notranslate nohighlight">\(k \leq n\)</span> und wir erhalten damit die triviale Zerlegung aus der ersten Behauptung.</p>
<p>Da <span class="math notranslate nohighlight">\(F\)</span> Endomorphismus ist folgt trivialerweise, dass <span class="math notranslate nohighlight">\(F(V_1) \subset V_1 = V\)</span> und <span class="math notranslate nohighlight">\(\dim(V_1) = \dim(V) = n\)</span> gilt, was die zweite Behauptung zeigt.</p>
<p>Da das charakteristische Polynom <span class="math notranslate nohighlight">\(P_F\)</span> von <span class="math notranslate nohighlight">\(F\)</span> in Linearfaktoren zerfällt wissen wir mit Satz <a class="reference internal" href="triag.html#satz:trigonalisierbarkeit">Theorem 1.7</a>, dass eine Basis <span class="math notranslate nohighlight">\(B\)</span> von <span class="math notranslate nohighlight">\(V\)</span> existiert, so dass die darstellende Matrix <span class="math notranslate nohighlight">\(M_B(F)\)</span> eine obere, rechte Dreiecksgestalt hat.
Wir können die darstellende Matrix dann zerlegen in <span class="math notranslate nohighlight">\(M_B(F) = D + N\)</span>, wobei <span class="math notranslate nohighlight">\(D\)</span> eine Diagonalmatrix der Form <span class="math notranslate nohighlight">\(D = \lambda E_n\)</span> ist und <span class="math notranslate nohighlight">\(N\)</span> eine strikte obere, rechte Dreiecksmatrix ist.
Mit Satz <a class="reference internal" href="#satz:nilpotent_charakterisierung">Theorem 1.10</a> wissen wir, dass <span class="math notranslate nohighlight">\(N\)</span> nilpotent sein muss.
Eine einfache Rechnung zeigt, dass <span class="math notranslate nohighlight">\(D\)</span> und <span class="math notranslate nohighlight">\(N\)</span> kommutieren mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
D \cdot N \ = \ \lambda \cdot N \ = \ N \cdot D,
\end{equation*}\]</div>
<p>womit die dritte Behauptung gezeigt ist.
~\[0.3cm]
\textbf{Induktionsschritt: <span class="math notranslate nohighlight">\(k-1 \rightarrow k\)</span>}\
Die Induktionsannahme ist, dass die Aussage bereits für den Fall <span class="math notranslate nohighlight">\(k-1\)</span> gezeigt wurde.
Wir definieren uns also für den Eigenwert <span class="math notranslate nohighlight">\(\lambda_1 \in \mathbb{K}\)</span> von <span class="math notranslate nohighlight">\(F\)</span> mit algebraischer Vielfachheit <span class="math notranslate nohighlight">\(r_1 \in \mathbb{N}, r_1 \geq 1\)</span> die Abbildung <span class="math notranslate nohighlight">\(G \ \coloneqq \ F - \lambda_1 \operatorname{Id}_V\)</span>. Seien <span class="math notranslate nohighlight">\(A\)</span> eine darstellende Matrix von <span class="math notranslate nohighlight">\(G\)</span> und <span class="math notranslate nohighlight">\(B\)</span> eine darstellende Matrix von <span class="math notranslate nohighlight">\(F\)</span> bezüglich einer beliebigen gemeinsamen Basis. Dann gilt offensichtlich <span class="math notranslate nohighlight">\(A = B - \lambda_1 I_n\)</span>. Damit sehen wir nun ein, dass gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\begin{split}
P_G(t-\lambda_1) \ &amp;= \ P_A(t - \lambda_1) \ = \ \det(A - (t - \lambda_1)I_n) \ \\
&amp;= \ \det(B - \lambda_1I_n - (t - \lambda_1)I_n) \ = \ \det(B - tI_n) \ = \ P_B(t) \ = \ P_F(t),
\end{split}
\end{equation*}\]</div>
<p>womit schon folgt, dass <span class="math notranslate nohighlight">\(0\)</span> ein Eigenwert von <span class="math notranslate nohighlight">\(G\)</span> mit algebraischer Vielfachheit <span class="math notranslate nohighlight">\(r_1\)</span> ist, da</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P_F(\lambda_1) \ = \ P_G(\lambda_1 - \lambda_1) \ = \ P_G(0). 
\end{equation*}\]</div>
<p>Nach dem Lemma <a class="reference internal" href="#lem:fitting">Lemma 1.8</a> von Fitting lässt sich <span class="math notranslate nohighlight">\(V\)</span> als direkte Summe schreiben mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
V \ = \ \operatorname{Haupt}(F; \lambda_1) \: \oplus \: \Bild(G^{r_1}).%\Bild( [F - \lambda_1 \operatorname{Id}_V]^{r_1} ).
\end{equation*}\]</div>
<p>Für <span class="math notranslate nohighlight">\(v \in \Hau(F; \lambda_1)\)</span> gilt, dass <span class="math notranslate nohighlight">\([F - \lambda_1 \operatorname{Id}_V]^{r_1} (v) = 0\)</span>.
Außerdem sieht man durch die Kommutativität der Identität ein, dass</p>
<div class="math notranslate nohighlight" id="equation-eq-kommutativ-identitat">
<span class="eqno">(1.15)<a class="headerlink" href="#equation-eq-kommutativ-identitat" title="Permalink to this equation">¶</a></span>\[[F - \lambda_1 \operatorname{Id}_V] (F(v)) \ = \ (F^2 - \lambda_1 F)(v) \ = \ F \circ (F - \lambda_1 \operatorname{Id}_V)(v)\]</div>
<p>und somit durch sukzessive Anwendung von \eqref{eq:kommutativ_identität} auch</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
[F - \lambda_1 \operatorname{Id}_V]^{r_1}(F(v)) \ = \ F \circ \underbrace{[F - \lambda_1 \operatorname{Id}_V]^{r_1}(v)}_{=0} \ = \ 0.
\end{equation*}\]</div>
<p>Das zeigt, dass <span class="math notranslate nohighlight">\(F(v) \in \Hau(F; \lambda_1)\)</span> für alle <span class="math notranslate nohighlight">\(v \in \Hau(F; \lambda_1)\)</span>, d.h, dass der Unterraum <span class="math notranslate nohighlight">\(\Hau(F; \lambda_1)\)</span> <span class="math notranslate nohighlight">\(F\)</span>-invariant ist.</p>
<p>Für <span class="math notranslate nohighlight">\(v \in V\)</span> gilt, dass <span class="math notranslate nohighlight">\(G^{r_1}(v) \eqqcolon w \in \Bild(G^{r_1})\)</span> ist.
Außerdem sehen wir ein, dass mit <span class="math notranslate nohighlight">\(F = (G + \lambda_1 \operatorname{Id}_V)\)</span> gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
F(w) \ = \ (G + \lambda_1 \operatorname{Id}_V)(w) \ = \ G(w) + \lambda_1 w = \ G \circ G^{r_1}(v) + \lambda_1 w \ \in \Bild(G^{r_1}),
\end{equation*}\]</div>
<p>da <span class="math notranslate nohighlight">\(\Bild(G^{r_1+1}) \subset \Bild(G^{r_1})\)</span> ist.
Das zeigt, dass <span class="math notranslate nohighlight">\(F(w) \in \Bild([F-\lambda_1 \operatorname{Id}_V]^{r_1})\)</span> für alle <span class="math notranslate nohighlight">\(w \in \Bild([F-\lambda_1 \operatorname{Id}_V]^{r_1})\)</span> ist, d.h., der Unterraum <span class="math notranslate nohighlight">\(\Bild([F-\lambda_1 \operatorname{Id}_V]^{r_1})\)</span> ist auch <span class="math notranslate nohighlight">\(F\)</span>-invariant.</p>
<p>Betrachten wir die Einschränkung <span class="math notranslate nohighlight">\(F|_W\)</span> von <span class="math notranslate nohighlight">\(F\)</span> auf den Unterraum <span class="math notranslate nohighlight">\(W\)</span> so stellen wir fest, dass das charakteristische Polynom <span class="math notranslate nohighlight">\(P_{F|_W}\)</span> in Linearfaktoren zerfällt mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P_{F|_W}(t) \ = \ \pm (t - \lambda_2)^{r_2} \cdot \ldots \cdot (t - \lambda_k)^{r_k}.
\end{equation*}\]</div>
<p>Da wir nun einen Endomorphismus betrachten, der <span class="math notranslate nohighlight">\(k-1\)</span> verschiedene Eigenwerte besitzt und dessen charakteristischen Polynom in Linearfaktoren zerfällt, können wir die Induktionsvoraussetzung anwenden.
Damit folgen direkt schon die ersten beiden Aussagen des Satzes.</p>
<p>Die Zerlegung aus der dritten Aussage des Satzes erhält man durch die folgenden darstellenden Matrizen in Blockdiagonalgestalt, die existieren, da der Endomorphismus <span class="math notranslate nohighlight">\(F\)</span> trigonalisierbar ist nach Satz <a class="reference internal" href="triag.html#satz:trigonalisierbarkeit">Theorem 1.7</a>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
D \ \coloneqq \
\begin{pmatrix}
\lambda_1 E_{r_1} &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \lambda_k E_{r_k}
\end{pmatrix}, \quad
N \ \coloneqq \
\begin{pmatrix}
N_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; N_k
\end{pmatrix}.
\end{equation*}\]</div>
<p>Man kann durch Nachrechnen leicht zeigen, dass gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
D \cdot N \ = \
\begin{pmatrix}
\lambda_1 N_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \lambda_k N_k
\end{pmatrix}
\ = \ N \cdot D.
\end{equation*}\]</div>
<p>Da <span class="math notranslate nohighlight">\(N\)</span> und <span class="math notranslate nohighlight">\(D\)</span> die darstellenden Matrizen der Endomorphismen <span class="math notranslate nohighlight">\(F_D\)</span> und <span class="math notranslate nohighlight">\(F_N\)</span> sind, folgt die Kommutativität jener.</p>
</div>
<p>Im Fall von Matrizen lässt sich die Aussage von Satz <a class="reference internal" href="#satz:hauptraumzerlegung">Theorem 1.11</a> wie folgt formulieren.</p>
<div class="proof corollary admonition" id="corollary-12">
<p class="admonition-title"><span class="caption-number">Corollary 1.3 </span></p>
<div class="corollary-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(A \in \mathbb{K}^{n \times n}\)</span> eine Matrix, für die das charakteristische Polynom <span class="math notranslate nohighlight">\(P_A\)</span> in Linearfaktoren zerfällt, d.h.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P_A(t) \ = \ \pm (t - \lambda_1)^{r_1} \cdot \ldots \cdot (t  - \lambda_k)^{r_k}.
\end{equation*}\]</div>
<p>Dann existiert eine invertierbare Matrix <span class="math notranslate nohighlight">\(S \in \GL(n; \mathbb{K})\)</span>, so dass</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
SAS^{-1} \ = 
\begin{pmatrix}
\lambda_1 I_{r_1} + N_1 &amp; &amp; 0\\
 &amp; \ddots &amp; \\
 0 &amp; &amp; \lambda_k I_{r_k} + N_k
\end{pmatrix}
\ =: \ \tilde{A}.
\end{equation*}\]</div>
<p>Jede Blockmatrix für <span class="math notranslate nohighlight">\(i=1,\ldots,k\)</span> hat hierbei die Gestalt einer rechten oberen Dreiecksmatrix, d.h.,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\lambda_i I_{r_i} + N_i \ = \ \begin{pmatrix} \lambda_i &amp; &amp; *\\ &amp; \ddots &amp; \\ 0 &amp; &amp; \lambda_i \end{pmatrix} \in \mathbb{K}^{r_i\times r_i}, \quad i=1,\ldots,k.
\end{equation*}\]</div>
<p>Insbesondere lässt sich die  Matrix <span class="math notranslate nohighlight">\(\tilde{A}\)</span> zerlegen in <span class="math notranslate nohighlight">\(\tilde{A} = D + N\)</span>, wobei <span class="math notranslate nohighlight">\(D\)</span> Diagonalmatrix und <span class="math notranslate nohighlight">\(N\)</span> nilpotent ist.
Schließlich gilt außerdem, dass <span class="math notranslate nohighlight">\(D\)</span> und <span class="math notranslate nohighlight">\(N\)</span> kommutieren, d.h.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
D \cdot N \ = \ N \cdot D.
\end{equation*}\]</div>
</div>
</div><div class="proof remark admonition" id="remark-13">
<p class="admonition-title"><span class="caption-number">Remark 1.5 </span></p>
<div class="remark-content section" id="proof-content">
<p>Die in Satz <a class="reference internal" href="#satz:hauptraumzerlegung">Theorem 1.11</a> beschriebene Zerlegung <span class="math notranslate nohighlight">\(F = F_D + F_N\)</span> ist die einzige Zerlegung in einen diagonalisierbaren und einen nilpotenten Endomorphismus, die kommutieren.</p>
</div>
</div></div>
<div class="section" id="normalisierung-nilpotenter-endomorphismen">
<h2><span class="section-number">1.6.4. </span>Normalisierung nilpotenter Endomorphismen<a class="headerlink" href="#normalisierung-nilpotenter-endomorphismen" title="Permalink to this headline">¶</a></h2>
<p>Die Hauptraumzerlegung liefert uns zwar eine Blockdiagonalmatrix, die der Gestalt einer vollbesetzten oberen, rechten Dreiecksmatrix vorzuziehen ist, jedoch geben wir uns noch nicht zufrieden mit diesem Resultat.
Bisher haben wir die nilpotenten Anteile des Endomorphismus als gegeben angesehen.
Es stellt sich jedoch heraus, dass es möglich ist diese durch geschickte Basiswahl in die Normalform einer Jordanmatrix in Definition <a class="reference internal" href="#def:normalform_nilpotent">Definition 1.13</a> zu überführen, wie der folgende Satz aussagt.</p>
<div class="proof theorem admonition" id="satz:normalform_nilpotent">
<p class="admonition-title"><span class="caption-number">Theorem 1.12 </span> (Normalisierung nilpotenter Endomorphismen)</p>
<div class="theorem-content section" id="proof-content">
<p>Es sei <span class="math notranslate nohighlight">\( G \in \End(V) \)</span> nilpotent mit Nilpotenzindex <span class="math notranslate nohighlight">\( d \in \mathbb{N} \)</span> über einem <span class="math notranslate nohighlight">\( \mathbb{K} \)</span>-Vektorraum <span class="math notranslate nohighlight">\( V \)</span>.
Dann gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\{0\}\subseteq
\Kern G \subseteq \Kern G^2
\subseteq \dots \subseteq 
\Kern G^d = V
\end{equation*}\]</div>
<p>und es gibt Koeffizienten <span class="math notranslate nohighlight">\( s_i \in \mathbb{N}, 1 \leq i \leq d \)</span>, so dass eine Zahlpartition existiert mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
s_1\cdot 1 + s_2\cdot 2 \dots + s_d \cdot d = n \coloneqq \Dim V.
\end{equation*}\]</div>
<p>Die Koeffizienten der Zahlpartition sind für den Endomorphismus <span class="math notranslate nohighlight">\(G\)</span> eindeutig festgelegt durch die folgende Differenz:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
s_i \ = \ \Delta_i - \Delta_{i+1}, \quad 1 \leq i \leq d,
\end{equation*}\]</div>
<p>wobei <span class="math notranslate nohighlight">\(\Delta_i \coloneqq \dim \Kern(G_i) - \dim \Kern(G_{i-1})\)</span> gerade die Anzahl der Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(i\)</span> sind.</p>
<p>Außerdem gibt es eine Basis <span class="math notranslate nohighlight">\( B \)</span> von <span class="math notranslate nohighlight">\( V \)</span>, so dass die darstellende Matrix von <span class="math notranslate nohighlight">\(G\)</span> bezüglich <span class="math notranslate nohighlight">\(B\)</span> eine Blockdiagonalmatrix mit folgender Gestalt ist</p>
<div class="math notranslate nohighlight" id="equation-equ-bjmf">
<span class="eqno">(1.16)<a class="headerlink" href="#equation-equ-bjmf" title="Permalink to this equation">¶</a></span>\[M_B(G)=
\diag\left(
\underset{s_d-\mathrm{mal}}{\underbrace{J_d,\dots,J_d}},
\underset{s_{d-1}-\mathrm{mal}}{\underbrace{J_{d-1},\dots,J_{d-1}}},
\dots\underset{s_{1}-\mathrm{mal}}{\underbrace{J_{1},\dots,J_{1}}} \right)\]</div>
<p>wobei, die Matrizen <span class="math notranslate nohighlight">\(J_k\)</span>, <span class="math notranslate nohighlight">\(1 \leq k \leq d\)</span>, <span class="math notranslate nohighlight">\(k\)</span>-dimensionale Jordanmatrizen aus Definition <a class="reference internal" href="#def:normalform_nilpotent">Definition 1.13</a> sind mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
J_k \ = \ \begin{pmatrix}
    0 &amp; 1 &amp;   &amp;   &amp; &amp; \\
    &amp; 0 &amp; 1 &amp;   &amp; \mathbf{0} &amp; \\
    &amp;   &amp; 0 &amp; 1 \\
    &amp; \mathbf{0}  &amp;   &amp;  \ddots &amp; \ddots 
\end{pmatrix} \in \mathbb{K}^{k \times k}.
\end{equation*}\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Siehe Theorem 4.6.5 <span id="id3">[<a class="reference internal" href="../references.html#id3">Fis05</a>]</span>.</p>
</div>
<p>Wir verzichten an dieser Stelle bewusst auf einen konstruktiven Beweis dieses wichtigen Satzes, da wir für ein vollständiges Verständnis viel mehr Theorie benötigen, die jedoch nicht Bestandteil dieser Vorlesung sein kann.
Diese unbefriedigende Lücke in der Normalformentheorie werden wir stattdessen mit der Diskussion eines Algorithmus zur Überführung der nilpotenten Anteile des Endomorphismus in die Normalform aus Satz <a class="reference internal" href="#satz:normalform_nilpotent">Theorem 1.12</a> füllen.</p>
<div class="proof algorithm admonition" id="alg:normalform_nilpotent">
<p class="admonition-title"><span class="caption-number">Algorithm 1.2 </span> (Normalisierung einer nilpotenten Matrix)</p>
<div class="algorithm-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(B\)</span> eine kanonische Basis des <span class="math notranslate nohighlight">\(\mathbb{K}\)</span>-Vektorraums <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(A \coloneqq M_B(G)\)</span> darstellende Matrix eines nilpotenten Endomorphismus <span class="math notranslate nohighlight">\(G \colon V \rightarrow V\)</span> mit Nilpotenzindex <span class="math notranslate nohighlight">\(d \in \mathbb{N}\)</span>.</p>
<p>Um eine Transformationsmatrix <span class="math notranslate nohighlight">\(S \in \GL(\mathbb{K}; n)\)</span> zu erhalten, so dass gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
N \ = \ S A S^{-1},
\end{equation*}\]</div>
<p>wobei <span class="math notranslate nohighlight">\(N\)</span> eine Jordanmatrix ist, müssen wir geschickt Basisvektoren aus den verschiedenen Kernen der Potenzen von <span class="math notranslate nohighlight">\(G\)</span> wählen.</p>
<p><strong>Vorbereitung</strong></p>
<ol class="simple">
<li><p>Berechne Potenzen von <span class="math notranslate nohighlight">\(A\)</span> als <span class="math notranslate nohighlight">\(A^i\)</span> für <span class="math notranslate nohighlight">\(1 \leq i \leq d\)</span></p></li>
<li><p>Bestimme Basen <span class="math notranslate nohighlight">\(K_i\)</span> der jeweiligen Kerne <span class="math notranslate nohighlight">\(\Kern(A^i)\)</span> für <span class="math notranslate nohighlight">\(1 \leq i \leq d\)</span></p></li>
<li><p>Berechne die Differenzen der aufeinanderfolgenden Kerndimensionen:
<span class="math notranslate nohighlight">\( \Delta_1 = \Dim\Kern(A) - \Dim\Kern(E_n)\)</span>, \dots, <span class="math notranslate nohighlight">\( \Delta_d = \Dim\Kern(A^d)-\Dim\Kern(A^{d-1}) \)</span></p></li>
</ol>
<p><strong>0. Schritt: Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(d\)</span></strong></p>
<ol class="simple">
<li><p>Wähle <span class="math notranslate nohighlight">\( s_d \coloneqq \Delta_d - \Delta_{d+1} = \Delta_d\)</span> Hauptvektoren <span class="math notranslate nohighlight">\( v^{(d)}_1,\dots, v_{s_d}^{(d)} \)</span> der Stufe <span class="math notranslate nohighlight">\(d\)</span> aus <span class="math notranslate nohighlight">\(K_d\)</span>
%aus <span class="math notranslate nohighlight">\( K_d \)</span>, welche linear unabhängig zu Vektoren aus <span class="math notranslate nohighlight">\( \Kern(A^{(d-1)}) \)</span> sind.</p></li>
<li><p>Notiere das Schema für den Aufbau von Jordanketten wie folgt</p></li>
</ol>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p><span class="math notranslate nohighlight">\( v^{(d)}_1 \)</span></p></th>
<th class="text-align:left head"><p><span class="math notranslate nohighlight">\( \dots \)</span></p></th>
<th class="text-align:left head"><p><span class="math notranslate nohighlight">\( v_{s_d}^{(d)}\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
</tr>
</tbody>
</table>
<p><strong>1. Schritt: Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(d-1\)</span></strong></p>
<ol class="simple">
<li><p>Multipliziere alle Vektoren des vorigen Schritts (die unterste Zeile im Schema) mit <span class="math notranslate nohighlight">\(A\)</span> und trage die resultierenden Vektoren <span class="math notranslate nohighlight">\( A v^{(d)}_1, \dots, A v_{s_d}^{(d)} \)</span> in eine neue Zeile <strong>unter</strong> das Schema ein.</p></li>
<li><p>Ergänze um <span class="math notranslate nohighlight">\( s_{d-1} = \Delta_{d-1}-\Delta_{d}\)</span> Hauptvektoren <span class="math notranslate nohighlight">\( v^{(d-1)}_1,\dots, v_{s_{d-1}}^{(d-1)} \)</span> der Stufe <span class="math notranslate nohighlight">\(d-1\)</span> aus <span class="math notranslate nohighlight">\(K_{d-1}\)</span> und trage sie <strong>rechts</strong> neben die unterste Zeile des Schemas ein.</p></li>
<li><p>Das resultierende Schema für den Aufbau von Jordanketten sollte die folgende Gestalt haben:</p></li>
</ol>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p><span class="math notranslate nohighlight">\( v^{(d)}_1 \)</span></p></th>
<th class="text-align:left head"><p><span class="math notranslate nohighlight">\( \dots \)</span></p></th>
<th class="text-align:left head"><p><span class="math notranslate nohighlight">\( v_{s_d}^{(d)} \)</span></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span class="math notranslate nohighlight">\( A v^{(d)}_1 \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( \dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( A v_{s_d}^{(d)} \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( v^{(d-1)}_1 \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( \dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( v_{s_{d-1}}^{(d-1)}\)</span></p></td>
</tr>
</tbody>
</table>
<p><strong><span class="math notranslate nohighlight">\(i\)</span>. Schritt: Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(d-i\)</span></strong></p>
<ol class="simple">
<li><p>Multipliziere alle Vektoren des vorigen Schritts (die unterste Zeile im Schema) mit <span class="math notranslate nohighlight">\(A\)</span> und trage die resultierenden Vektoren in eine neue Zeile <strong>unter</strong> das Schema ein.</p></li>
<li><p>Ergänze um <span class="math notranslate nohighlight">\( s_{d-i} = \Delta_{d-i} - \Delta_{d-i+1}\)</span> Hauptvektoren <span class="math notranslate nohighlight">\( v^{(d-i)}_1,\dots, v^{(d-i)}_{s_{d-i}} \)</span> der Stufe <span class="math notranslate nohighlight">\(d-i\)</span> aus <span class="math notranslate nohighlight">\(K_{d-i}\)</span> und trage sie \textbf{rechts} neben die unterste Zeile des Schemas ein.</p></li>
<li><p>Das resultierende Schema für den Aufbau von Jordanketten sollte die folgende Gestalt haben:</p></li>
</ol>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></th>
<th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></th>
<th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span class="math notranslate nohighlight">\( A^{i-1}v^{(d)}_1 \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(\dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( A^{i-1}v^{(d)}_{s_d}\)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( \dots\)</span></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span class="math notranslate nohighlight">\( A^{i}v^{(d)}_1 \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(\dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( A^{i}v^{(d)}_{s_d} \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( \dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( v^{(d-i)}_1 \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(\dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( v^{(d-i)}_{s_{d-i}}\)</span></p></td>
</tr>
</tbody>
</table>
<p><strong><span class="math notranslate nohighlight">\(d-1\)</span>. Schritt: Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(1\)</span></strong></p>
<ol class="simple">
<li><p>Multipliziere alle Vektoren des vorigen Schritts (die unterste Zeile im Schema) mit <span class="math notranslate nohighlight">\(A\)</span> und trage die resultierenden Vektoren in eine neue Zeile <strong>unter</strong> das Schema ein.</p></li>
<li><p>Ergänze um <span class="math notranslate nohighlight">\( s_{1} = \Delta_{1} - \Delta_{2}\)</span> Hauptvektoren <span class="math notranslate nohighlight">\( v^{(1)}_1,\dots, v^{(1)}_{s_{1}} \)</span> der Stufe <span class="math notranslate nohighlight">\(1\)</span> aus <span class="math notranslate nohighlight">\(K_1 = \Eig(G; \lambda)\)</span>, also <strong>Eigenvektoren</strong>, und trage sie <strong>rechts</strong> neben die unterste Zeile des Schemas ein.</p></li>
<li><p>Das resultierende Schema für den Aufbau von Jordanketten sollte die folgende Gestalt haben:</p></li>
</ol>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></th>
<th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></th>
<th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\vdots\)</span></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span class="math notranslate nohighlight">\(A^{d-2}v^{(d)}_1 \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(\dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( A^{d-2}v^{(d)}_{s_d}\)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( \dots \)</span></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span class="math notranslate nohighlight">\( A^{d-1}v^{(d)}_1 \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(\dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( A^{d-1}v^{(d)}_{s_d}\)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( \dots \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( v^{(1)}_1 \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(\dots \)</span></p></td>
<td class="text-align:left"><p>$ v^{(1)}_{s_1}</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p><span class="math notranslate nohighlight">\( \uparrow \)</span></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\( \uparrow \)</span></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>\text{ Jordankette }</p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p>\text{ Jordankette }</p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
<td class="text-align:left"><p></p></td>
</tr>
</tbody>
</table>
<p><strong>Spaltenweises Eintragen des Schemas in <span class="math notranslate nohighlight">\(S^{-1}\)</span>:</strong></p>
<p>Lesen wir die schließlich das fertige Schema zuerst von <strong>unten nach oben</strong> und dann von <strong>links nach rechts</strong> (entlang der Jordanketten) zellenweise ab und notieren die so gefundenen Vektoren <strong>spaltenweise</strong> von links nach rechts in die Transformationsmatrix <span class="math notranslate nohighlight">\(S^{-1}\)</span>, so liegt <span class="math notranslate nohighlight">\( N = S A S^{-1} \)</span> in der Normalform nilpotenter Endomorphismen in Definition <a class="reference internal" href="#def:normalform_nilpotent">Definition 1.13</a> vor.</p>
</div>
</div></div>
<div class="section" id="jordansche-normalform">
<h2><span class="section-number">1.6.5. </span>Jordansche Normalform<a class="headerlink" href="#jordansche-normalform" title="Permalink to this headline">¶</a></h2>
<p>Durch geschickte Kombination der Hauptraumzerlegung aus Satz <a class="reference internal" href="#satz:hauptraumzerlegung">Theorem 1.11</a> und der Normalform niolpotenter Endormorphismen in Satz <a class="reference internal" href="#satz:normalform_nilpotent">Theorem 1.12</a> lässt sich eine kanonische Normalform für Endomorphismen bestimmen, die schöne Eigenschaften hat.
Diese <em>Jordansche Normalform</em> wird im folgenden Satz näher beschrieben.</p>
<div class="proof theorem admonition" id="satz:normalform_jordan">
<p class="admonition-title"><span class="caption-number">Theorem 1.13 </span> (Jordansche Normalform)</p>
<div class="theorem-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(A \in \mathbb{K}^{n \times n}\)</span> eine Matrix, für die das charakteristische Polynom <span class="math notranslate nohighlight">\(P_A\)</span> in Linearfaktoren zerfällt, d.h.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P_A(t) \ = \ \pm (t - \lambda_1)^{r_1} \cdot \ldots \cdot (t  - \lambda_k)^{r_k}.
\end{equation*}\]</div>
<p>Dann existiert eine invertierbare Matrix <span class="math notranslate nohighlight">\(S \in \GL(n; \mathbb{K})\)</span>, so dass</p>
<div class="math notranslate nohighlight" id="equation-eq-jordannormalform">
<span class="eqno">(1.17)<a class="headerlink" href="#equation-eq-jordannormalform" title="Permalink to this equation">¶</a></span>\[\begin{split}SAS^{-1} \ = \
\begin{pmatrix}
\lambda_1 I_{r_1} + N_1 &amp; &amp; 0\\
 &amp; \ddots &amp; \\
 0 &amp; &amp; \lambda_k I_{r_k} + N_k \\
\end{pmatrix}
=: \ J.\end{split}\]</div>
<p>Die nilpotenten Anteile <span class="math notranslate nohighlight">\(N_i\)</span> für <span class="math notranslate nohighlight">\(i=1,\ldots,k\)</span> liegen hierbei (blockweise) in der Normalform aus Definition <a class="reference internal" href="#def:normalform_nilpotent">Definition 1.13</a> vor. Die Blockmatrizen <span class="math notranslate nohighlight">\(\lambda_i I_{r_i} + N_i \in \mathbb{K}^{r_i \times r_i}\)</span> in <span class="math notranslate nohighlight">\(J\)</span> werden \emph{Jordanblöcke} genannt und sind von der Gestalt</p>
<div class="math notranslate nohighlight" id="equation-eq-jordanblock">
<span class="eqno">(1.18)<a class="headerlink" href="#equation-eq-jordanblock" title="Permalink to this equation">¶</a></span>\[\begin{split}\lambda_i I_{r_i} + N_i \ = \ 
\begin{pmatrix}
 \lambda_i &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp;\\
&amp; \ddots &amp; \ddots &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp;\\
&amp; &amp; \ddots &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; &amp;\\
&amp; &amp; &amp; \lambda_i &amp; 0 &amp; &amp; &amp; &amp; &amp; &amp;\\
&amp; &amp; &amp; &amp; \lambda_i &amp; 1 &amp; &amp; &amp; &amp; &amp;\\
&amp; &amp; &amp; &amp; &amp; \ddots &amp; \ddots &amp; &amp; &amp; &amp;\\
&amp; &amp; &amp; &amp; &amp; &amp; \ddots &amp; 1 &amp; &amp; &amp;\\
&amp; &amp; &amp; &amp; &amp; &amp; &amp; \lambda_i &amp; 0 &amp; &amp;\\
&amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; \ddots &amp; \ddots &amp;\\
&amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; \ddots &amp; 0 \\
&amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp;  &amp; \lambda_i \\
\end{pmatrix}\end{split}\]</div>
<p>Die <strong>Anzahl der Kästchen</strong> in einem Jordanblock der Form \eqref{eq:jordanblock} ist gegeben durch die <strong>geometrische Vielfachheit</strong> , <span class="math notranslate nohighlight">\(\dim \Eig(F - \lambda_i I_n)\)</span> des Eigenwerts <span class="math notranslate nohighlight">\(\lambda_i \in \mathbb{K}\)</span> von <span class="math notranslate nohighlight">\(F\)</span>.
Insbesondere lässt sich die Jordansche Normalform <span class="math notranslate nohighlight">\(J\)</span> von <span class="math notranslate nohighlight">\(A\)</span> zerlegen in <span class="math notranslate nohighlight">\(J= D + N\)</span>, wobei <span class="math notranslate nohighlight">\(D\)</span> Diagonalmatrix und <span class="math notranslate nohighlight">\(N\)</span> nilpotent ist.
Schließlich gilt außerdem, dass <span class="math notranslate nohighlight">\(D\)</span> und <span class="math notranslate nohighlight">\(N\)</span> kommutieren, d.h.</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
D \cdot N \ = \ N \cdot D.
\end{equation*}\]</div>
</div>
</div><div class="proof admonition" id="proof">
<p>Proof. Der Beweis der Jordanschen Normalform besteht im Prinzip nur aus Anwendung der Hauptraumzerlegung aus Satz <a class="reference internal" href="#satz:hauptraumzerlegung">Theorem 1.11</a> und dem Satz <a class="reference internal" href="#satz:normalform_nilpotent">Theorem 1.12</a> über die Normalform für nilpotente Endomorphismen.
Wir bezeichnen für <span class="math notranslate nohighlight">\(i = 1, \ldots, k\)</span> die Haupträume von <span class="math notranslate nohighlight">\(F\)</span> bezüglich der Eigenwerte <span class="math notranslate nohighlight">\(\lambda_i\)</span> mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
V_i \ \coloneqq \ \Hau(F; \lambda_i),
\end{equation*}\]</div>
<p>und wir betrachten die nilpotenten Endomorphismen</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
G_i \ \coloneqq \ (F - \lambda_i \operatorname{Id}_V)|_{V_i}.
\end{equation*}\]</div>
<p>Durch Anwendung des Satzes <a class="reference internal" href="#satz:normalform_nilpotent">Theorem 1.12</a> können wir Basen <span class="math notranslate nohighlight">\(B_i\)</span> der Haupträume <span class="math notranslate nohighlight">\(V_i\)</span> finden, so dass die darstellenden Matrizen <span class="math notranslate nohighlight">\(M_{B_i}(G_i)\)</span> der nilpotenten Endomorphismen in Normalform vorliegen.
Diese Basen kann man dann wegen der Hauptraumzerlegung in Satz <a class="reference internal" href="#satz:hauptraumzerlegung">Theorem 1.11</a> zu einer Basis <span class="math notranslate nohighlight">\(B\)</span> von <span class="math notranslate nohighlight">\(V\)</span> zusammenführen, so dass die darstellende Matrix <span class="math notranslate nohighlight">\(M_B(F)\)</span> in Jordanscher Normalform vorliegt.</p>
</div>
<div class="proof algorithm admonition" id="alg:normalform_jordan">
<p class="admonition-title"><span class="caption-number">Algorithm 1.3 </span> (Berechnung der Jordannormalform)</p>
<div class="algorithm-content section" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(B\)</span> eine kanonische Basis des <span class="math notranslate nohighlight">\(\mathbb{K}\)</span>-Vektorraums <span class="math notranslate nohighlight">\(V\)</span> und <span class="math notranslate nohighlight">\(A \coloneqq M_B(F)\)</span> darstellende Matrix eines Endomorphismus <span class="math notranslate nohighlight">\(F \colon V \rightarrow V\)</span>, dessen charakteristisches Polynom in Linearfaktoren zerfällt von der Gestalt ist</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
P_F(t) \ = \ \pm (t- \lambda_1)^{r_1} \cdot \ldots \cdot (t-\lambda_k)^r_k
\end{equation*}\]</div>
<p>für <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span> paarweise verschiedene Eigenwerte von <span class="math notranslate nohighlight">\(F\)</span>.</p>
<p>Das Ziel ist es eine Transformationsmatrix <span class="math notranslate nohighlight">\(S \in \GL(\mathbb{K}; n)\)</span> zu konstruieren, so dass gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
J \ = \ S A S^{-1},
\end{equation*}\]</div>
<p>wobei <span class="math notranslate nohighlight">\(J\)</span> die Jordannormalform aus <a class="reference internal" href="#equation-eq-jordannormalform">(1.17)</a> ist.</p>
<p>Hierfür müssen wir nur die nilpotenten Einschränkungen von <span class="math notranslate nohighlight">\(F\)</span> auf die Haupträume <span class="math notranslate nohighlight">\(V_i \coloneqq \Hau(F; \lambda_i)\)</span> mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
G_i \ \coloneqq \ (F-\lambda_i I_{r_i})|_{V_i}, \quad 1\leq i\leq k
\end{equation*}\]</div>
<p>betrachten und die nötigen Basen <span class="math notranslate nohighlight">\(B_i\)</span> von <span class="math notranslate nohighlight">\(\Hau(F; \lambda_i)\)</span> mit dem Algorithmus <a class="reference internal" href="#alg:normalform_nilpotent">Algorithm 1.2</a> zur Normalisierung von nilpotenten Endomorphismen berechnen.
Die Konkatenation der Basen <span class="math notranslate nohighlight">\(B_i, 1 \leq i \leq k\)</span> ergibt wegen dem Satz zur Hauptraumzerlegung <a class="reference internal" href="#satz:hauptraumzerlegung">Theorem 1.11</a> eine Basis des Vektorraums <span class="math notranslate nohighlight">\(V\)</span>.
Werden die Basisvektoren spaltenweise in die Transformationsmatrix <span class="math notranslate nohighlight">\(S^{-1}\)</span> eingetragen, so erhält man unter dieser Ähnlichkeitstransformation die gewünschte Jordansche Normalform <span class="math notranslate nohighlight">\(J\)</span> von <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>Diese Jordansche Normalform <span class="math notranslate nohighlight">\(J\)</span> ist eindeutig bis auf Permutation der Jordanblöcke.</p>
</div>
</div><p>Wir wollen ein abschließendes Beispiel zur Jordanschen Normalform für eine <span class="math notranslate nohighlight">\((5 \times 5)\)</span>-Matrix durchrechnen.</p>
<div class="proof example admonition" id="example-18">
<p class="admonition-title"><span class="caption-number">Example 1.8 </span> (Berechnung der Jordanschen Normalform mit Transformationsmatrix)</p>
<div class="example-content section" id="proof-content">
<p>Wir betrachten die Matrix</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
	A\ \coloneqq \ \begin{pmatrix}
        5 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        -1 &amp; 0 &amp; 3 &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{3}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 4
    \end{pmatrix}
\end{equation*}\]</div>
<p>Um die Matrix <span class="math notranslate nohighlight">\(A\)</span> in eine Jordansche Normalform zu überführen verwenden wir Algorithmus <a class="reference internal" href="#alg:normalform_nilpotent">Algorithm 1.2</a> und <a class="reference internal" href="#alg:normalform_jordan">Algorithm 1.3</a>.</p>
<p>Wir berechnen zuerst alle Eigenwerte von <span class="math notranslate nohighlight">\(A\)</span> mit Hilfe des charakteristischen Polynoms:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\begin{split}
	P_A(\lambda) \ &amp;= \
	\det\begin{pmatrix}
        5-\lambda &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2}-\lambda &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        -1 &amp; 0 &amp; 3-\lambda &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{3}{2}-\lambda &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 4-\lambda
    \end{pmatrix}        
    \\
    \ &amp;= \ (-1)^{5+5}(4-\lambda)
      	\det\begin{pmatrix}
        5-\lambda &amp; 0 &amp; 1 &amp; 0 \\
        0 &amp; \frac{1}{2}-\lambda &amp; 0 &amp; -\frac{1}{2} \\
        -1 &amp; 0 &amp; 3-\lambda &amp; 0  \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{3}{2}-\lambda \\
        \end{pmatrix}
    \\
    \ &amp;= \
    (4-\lambda)\left[
      	(-1)^{4+2}\frac{1}{2}\det\begin{pmatrix}
            5-\lambda &amp; 1 &amp; 0 \\
            0 &amp; 0 &amp; -\frac{1}{2}\\
            -1 &amp; 3-\lambda &amp; 0
        \end{pmatrix} \right.
       \\
        &amp;\qquad \qquad \left. + \ (-1)^{4+4}(\frac{3}{2}-\lambda)
        \det
        \begin{pmatrix}
            5-\lambda &amp; 0 &amp; 1 \\
            0 &amp; \frac{1}{2}-\lambda &amp; 0 \\
            -1 &amp; 0 &amp; 3-\lambda
        \end{pmatrix} \right]
     \\
    &amp;=
    (4-\lambda) \left[
    	\frac{1}{2}(-1)^{2+3}(-\frac{1}{2})\det
        \begin{pmatrix}
            5-\lambda &amp; 1 \\
            -1 &amp; 3-\lambda
        \end{pmatrix} \right.
        \\
        &amp; \qquad \qquad \left. +
        (\frac{3}{2}-\lambda)(-1)^{2+2}(\frac{1}{2}-\lambda)
        \det
        \begin{pmatrix}
            5-\lambda &amp; 1 \\
            -1 &amp; 3-\lambda
        \end{pmatrix}
    \right]
    \\
    &amp;=
(4-\lambda) \left[
    	\frac{1}{4}\Bigl((5-\lambda)(3-\lambda)+1\Bigr)
        +
        (\frac{3}{2}-\lambda)(\frac{1}{2}-\lambda)\Bigl((5-\lambda)(3-\lambda)+1\Bigr)
    \right]
    \\
    &amp;=
    (4-\lambda)\Bigl((5-\lambda)(3-\lambda)+1\Bigr)
    \left(\frac{1}{4}+(\frac{3}{2}-\lambda)(\frac{1}{2}-\lambda)\right)
    \\
    &amp;=
    (4-\lambda)(16-8\lambda+\lambda^2)(1-2\lambda+\lambda^2)
    \\
    &amp;=
    (4-\lambda)^3(1-\lambda)^2.
\end{split}
\end{equation*}\]</div>
<p>Es liegen somit die Eigenwerte <span class="math notranslate nohighlight">\( \lambda_1 = 1 \)</span> und <span class="math notranslate nohighlight">\( \lambda_2 = 4 \)</span> von <span class="math notranslate nohighlight">\(A\)</span> mit den jeweiligen algebraischen Vielfachheiten <span class="math notranslate nohighlight">\( r_1 = 2 \)</span> und <span class="math notranslate nohighlight">\( r_2 = 3 \)</span> vor.</p>
<p>Für den \textbf{ersten Jordanblock} zum Eigenwert <span class="math notranslate nohighlight">\(\lambda_1 = 1\)</span> von <span class="math notranslate nohighlight">\(A\)</span> betrachten wir zunächst den Endomorphismus</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
	G_1 \ \coloneqq \
    A - 1 \cdot I_5
    \ = \
    \begin{pmatrix}
        4 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; -\frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        -1 &amp; 0 &amp; 2  &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 3
    \end{pmatrix}
\end{equation*}\]</div>
<p>und wenden Algorithmus <a class="reference internal" href="#alg:normalform_nilpotent">Algorithm 1.2</a> zur Bestimmung einer Normalform an.</p>
<p><strong>Vorbereitung</strong></p>
<p>Wir bestimmen eine Basis <span class="math notranslate nohighlight">\(K_1\)</span> des Eigenraums <span class="math notranslate nohighlight">\( \Kern(G_1) \)</span> mittels Gaußschen Eliminiationsverfahren:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    &amp;\begin{pmatrix}
        4 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; -\frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        -1 &amp; 0 &amp; 2  &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 3
    \end{pmatrix}
    \overset{I + 4 \cdot III}{\mapsto}
    \begin{pmatrix}
        0 &amp; 0 &amp; 9 &amp; 0 &amp; 0 \\
        0 &amp; -\frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        -1 &amp; 0 &amp; 2  &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 3
    \end{pmatrix}
    \overset{I\leftrightarrow III}{\mapsto}\\
    &amp;\begin{pmatrix}
        -1 &amp; 0 &amp; 2  &amp; 0 &amp; 0 \\
        0 &amp; -\frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 9 &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; \frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 3
    \end{pmatrix}
    \overset{IV + II}{\mapsto}
    \begin{pmatrix}
        -1 &amp; 0 &amp; 2  &amp; 0 &amp; 0 \\
        0 &amp; -\frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 9 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 3
    \end{pmatrix}    \overset{IV\leftrightarrow V}{\mapsto}\\
    &amp;\begin{pmatrix}
        -1 &amp; 0 &amp; 2  &amp; 0 &amp; 0 \\
        0 &amp; -\frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 9 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 3\\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    \end{pmatrix}.
\end{align*}\]</div>
<p>Wir erhalten also als mögliche Basis</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
K_1 \ \coloneqq \ \left\{
\begin{pmatrix}
    0 \\ 1 \\ 0 \\ -1 \\ 0
\end{pmatrix}
\right\}.
\end{equation*}\]</div>
<p>Da <span class="math notranslate nohighlight">\(\dim K_1 = \dim \Eig(A; 1) = 1\)</span> gilt, wissen wir nach Satz <a class="reference internal" href="#satz:normalform_jordan">Theorem 1.13</a>, dass es nur ein Jordankästchen innerhalb des Jordanblocks zum Eigenwert <span class="math notranslate nohighlight">\(\lambda_1 = 1\)</span> von <span class="math notranslate nohighlight">\(A\)</span> geben kann.
Die Größe dieses Jordankästchens entspricht in diesem Fall der algebraischen Vielfachheit <span class="math notranslate nohighlight">\(r_1 = 2\)</span> von <span class="math notranslate nohighlight">\(\lambda_1\)</span>.</p>
<p>Wir bestimmen nun eine Basis <span class="math notranslate nohighlight">\(K_2\)</span> des Eigenraums <span class="math notranslate nohighlight">\( \Kern(G_1^2) \)</span> mittels Gaußschen Eliminationsverfahren mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
G_1^2
\ = \
\begin{pmatrix}
    15 &amp; 0 &amp; 6 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
    -6 &amp; 0 &amp; 3 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 9
\end{pmatrix}
\end{equation*}\]</div>
<p>und erhalten somit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    &amp;\begin{pmatrix}
        15 &amp; 0 &amp; 6 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
        -6 &amp; 0 &amp; 3 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 9
    \end{pmatrix}
    \overset{II\leftrightarrow V \&amp; II \leftrightarrow III}{\mapsto}
    \begin{pmatrix}
        15 &amp; 0 &amp; 6 &amp; 0 &amp; 0 \\
        -6 &amp; 0 &amp; 3 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 9\\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
    \end{pmatrix}
    \overset{2 \cdot I \&amp; 5 \cdot II}{\mapsto}
    \\
    &amp;\begin{pmatrix}
        30 &amp; 0 &amp; 12 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
        -30 &amp; 0 &amp; 15 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 9
    \end{pmatrix}
    \overset{II+I}{\mapsto}
    \begin{pmatrix}
        30 &amp; 0 &amp; 12 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 27 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 9
    \end{pmatrix}.
\end{align*}\]</div>
<p>Wir erhalten somit als mögliche Basis von <span class="math notranslate nohighlight">\(\Kern(G_1^2)\)</span></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
K_2 
    \ \coloneqq \ \left\{
      \begin{pmatrix}
          0 \\ 1\\ 0 \\ -1 \\ 0
      \end{pmatrix},
      \begin{pmatrix}
          0 \\ -1\\ 0 \\ -1 \\ 0
      \end{pmatrix}
    \right\}.
\end{equation*}\]</div>
<p>Wir haben den Nilpotenzindex von <span class="math notranslate nohighlight">\(d = 2\)</span> von <span class="math notranslate nohighlight">\(G_1|_{\Hau(A; \lambda_1)}\)</span> erreicht.
Das bedeutet, dass der Kern von <span class="math notranslate nohighlight">\(G_1\)</span> sich nicht mehr ändert für jede weitere Potenz von <span class="math notranslate nohighlight">\(G_1\)</span>, da gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
2 \ = \ \dim \Kern(G_1^2) \ = \ \dim \Hau(A; 1) \ = \ r_1.
\end{equation*}\]</div>
<p>Entsprechend brauchen wir keine weiteren Potenzen von <span class="math notranslate nohighlight">\( G_1 \)</span> mehr zu betrachten.</p>
<p>Wir berechnen abschließend zur Vorbereitung</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Delta_2 \, \coloneqq \, \dim K_2 - \dim K_1 \, = \, 2 - 1 \, = \, 1, \quad \Delta_1 \, \coloneqq \, \dim K_1 \, = \, 1.
\end{equation*}\]</div>
<p><strong>1. Schritt: Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(2\)</span></strong></p>
<p>Wir wählen aus dem Kern <span class="math notranslate nohighlight">\( K_2 \)</span> einen (<span class="math notranslate nohighlight">\(\Delta_2 = 1 \)</span>) Hauptvektor der Stufe <span class="math notranslate nohighlight">\(2\)</span>, d.h., einen Vektor der linear unabhängig zu Vektoren aus <span class="math notranslate nohighlight">\( K_1 \)</span> ist, also beispielsweise <span class="math notranslate nohighlight">\(  (0,-1,0,-1,0)^T \)</span>.
Wir notieren diesen Vektor in ein Schema wie folgt:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\begin{pmatrix}0\\-1\\0\\-1\\0\end{pmatrix}\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p></p></td>
</tr>
</tbody>
</table>
<p><strong>2. Schritt: Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(1\)</span></strong></p>
<p>Wir berechnen zunächst <span class="math notranslate nohighlight">\( G_1 \cdot (0,-1,0,-1,0)^T = (0,1,0,-1,0)^T\)</span> und tragen diesen Vektor in einer neuen Zeile unten in das Schema ein.
Wir berechnen</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
s_1 \, = \, \Delta_1 - \Delta_2 \, = \, 1 - 1 \, = \, 0,
\end{equation*}\]</div>
<p>also brauchen wir keine weiteren Vektoren hinzufügen.
Dies ist konsistent zu der Beobachtung, dass das Schema bereits <span class="math notranslate nohighlight">\(r_1 = 2\)</span> Vektoren enthält.</p>
<p>Das finale Schema für den <strong>ersten Jordanblock</strong> sieht entsprechend so aus:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\begin{pmatrix}0\\-1\\0\\-1\\0\end{pmatrix}\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>$\begin{pmatrix} 0\1\0-1\0 \end{pmatrix}</p></td>
</tr>
</tbody>
</table>
<p>Die Basis <span class="math notranslate nohighlight">\( B_1 \)</span> für den Hauptraum <span class="math notranslate nohighlight">\(\Hau(A; 1)\)</span> von <span class="math notranslate nohighlight">\(A\)</span> zum Eigenwert <span class="math notranslate nohighlight">\(\lambda_1 = 1\)</span> ergibt sich entsprechend durch Ablesen des Schemas
<em>von unten nach oben, von links nach rechts</em>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
B_1 \ \coloneqq \ 
\begin{pmatrix}
    0 &amp; 0  \\ 1 &amp; -1  \\ 0 &amp; 0  \\ -1 &amp; -1 \\ 0 &amp; 0
\end{pmatrix}
\end{equation*}\]</div>
<p>Für den <strong>zweiten Jordanblock</strong> zum Eigenwert <span class="math notranslate nohighlight">\(\lambda_1 = 4\)</span> von <span class="math notranslate nohighlight">\(A\)</span> betrachten wir zunächst den Endomorphismus</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
G_2 \ \colonequals \ A - 4\cdot I_5 \ = \
\begin{pmatrix}
    1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
    0 &amp; -\frac{7}{2}&amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
    -1 &amp; 0 &amp; -1 &amp; 0 &amp; 0 \\
    0 &amp; \frac{1}{2} &amp; 0 &amp; -\frac{5}{2} &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 
\end{pmatrix}
\end{equation*}\]</div>
<p>und wenden <a class="reference internal" href="#alg:normalform_nilpotent">Algorithm 1.2</a> zur Bestimmung einer Normalform an.</p>
<p><strong>Vorbereitung</strong></p>
<p>Wir bestimmen eine Basis <span class="math notranslate nohighlight">\(K_1\)</span> des Eigenraums <span class="math notranslate nohighlight">\( \Kern(G_2) \)</span> mittels Gaußschen Eliminiationsverfahren:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    &amp;\begin{pmatrix}
        1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; -\frac{7}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        -1 &amp; 0 &amp; -1 &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp;-\frac{5}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 
    \end{pmatrix}
    \overset{III+I}{\mapsto}
    \begin{pmatrix}
        1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; -\frac{7}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; -\frac{5}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 
    \end{pmatrix}
    \overset{III\leftrightarrow IV}\mapsto
    \\
    &amp;\begin{pmatrix}
        1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp;  -\frac{7}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; -\frac{5}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 
    \end{pmatrix}
    \overset{II\leftrightarrow III}{\mapsto}
    \begin{pmatrix}
        1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp; -\frac{5}{2} &amp; 0 \\
        0 &amp; -\frac{7}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 
    \end{pmatrix}
    \overset{III + 7\cdot II}{\mapsto}
    \\
    &amp;\begin{pmatrix}
        1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
        0 &amp; \frac{1}{2} &amp; 0 &amp;-\frac{5}{2} &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; -18 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 
    \end{pmatrix}
\end{align*}\]</div>
<p>Wir erhalten also als mögliche Basis</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
K_1 \ \coloneqq \ \left\{
      \begin{pmatrix}
          1 \\ 0 \\ -1 \\ 0 \\ 0
      \end{pmatrix},
      \begin{pmatrix}
          0 \\ 0 \\ 0 \\ 0 \\ 1
      \end{pmatrix}
   \right\}.
\end{equation*}\]</div>
<p>Da <span class="math notranslate nohighlight">\(\dim K_1 = \dim \Eig(A; 4) = 2\)</span> gilt, wissen wir nach Satz <a class="reference internal" href="#satz:normalform_jordan">Theorem 1.13</a>, dass es zwei Jordankästchen innerhalb des Jordanblocks zum Eigenwert <span class="math notranslate nohighlight">\(\lambda_2 = 4\)</span> von <span class="math notranslate nohighlight">\(A\)</span> gibt.
Die Summe der Größen dieser Jordankästchen entspricht in diesem Fall der algebraischen Vielfachheit <span class="math notranslate nohighlight">\(r_2 = 3\)</span> von <span class="math notranslate nohighlight">\(\lambda_2\)</span>.</p>
<p>Wir bestimmen nun eine Basis <span class="math notranslate nohighlight">\(K_2\)</span> des Eigenraums <span class="math notranslate nohighlight">\( \Kern(G_2^2) \)</span> mittels Gaußschen Eliminiationsverfahren mit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
G_2^2 \ = \
    \begin{pmatrix}
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 12 &amp; 0 &amp; 3 &amp; 0 \\
        0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
        0 &amp; -3 &amp; 0 &amp; 6 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
    \end{pmatrix}
\end{equation*}\]</div>
<p>und erhalten somit</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    \begin{pmatrix}
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 12 &amp; 0 &amp; 3 &amp; 0 \\
        0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
        0 &amp; -3 &amp; 0 &amp; 6 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
    \end{pmatrix}
    \overset{I\leftrightarrow IV}{\mapsto}
    \begin{pmatrix}
        0 &amp; -3 &amp; 0 &amp; 6 &amp; 0 \\
        0 &amp; 12 &amp; 0 &amp; 3 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
    \end{pmatrix}
    \overset{II + 4\cdot I}{\mapsto}
    \begin{pmatrix}
        0 &amp; -3 &amp; 0 &amp; 6 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 27 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0&amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 0
    \end{pmatrix}.
\end{equation*}\]</div>
<p>Wir erhalten somit als mögliche Basis von <span class="math notranslate nohighlight">\(\Kern(G_1^2)\)</span></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
K_2 \ \coloneqq \ \left\{
      \begin{pmatrix}
          1 \\ 0 \\ 0 \\ 0 \\ 0
      \end{pmatrix},
      \begin{pmatrix}
          0 \\ 0 \\ 1 \\ 0 \\ 0
      \end{pmatrix},
      \begin{pmatrix}
          0 \\ 0 \\ 0 \\ 0 \\ 1
      \end{pmatrix}
    \right\}.
\end{equation*}\]</div>
<p>Wir haben den Nilpotenzindex von <span class="math notranslate nohighlight">\(d = 3\)</span> von <span class="math notranslate nohighlight">\(G_2|_{\Hau(A; \lambda_2)}\)</span> erreicht.
Das bedeutet, dass der Kern von <span class="math notranslate nohighlight">\(G_2\)</span> sich nicht mehr ändert für jede weitere Potenz von <span class="math notranslate nohighlight">\(G_2\)</span>, da gilt</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
3 \ = \ \dim \Kern(G_2^2) \ = \ \dim \Hau(A; 4) \ = \ r_2.
\end{equation*}\]</div>
<p>Entsprechend brauchen wir keine weiteren Potenzen von <span class="math notranslate nohighlight">\( G_2 \)</span> zu betrachten.</p>
<p>Wir berechnen abschließend zur Vorbereitung</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Delta_2 \, \coloneqq \, \dim K_2 - \dim K_1 \, = \, 3 - 2 \, = \, 1, \quad \Delta_1 \, \coloneqq \, \dim K_1 \, = \, 2.
\end{equation*}\]</div>
<p><strong>1. Schritt: Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(2\)</span></strong></p>
<p>Wir wählen aus dem Kern <span class="math notranslate nohighlight">\( K_2 \)</span> einen (<span class="math notranslate nohighlight">\(\Delta_2 = 1 \)</span>) Hauptvektor der Stufe <span class="math notranslate nohighlight">\(2\)</span>, d.h., einen Vektor der linear unabhängig zu Vektoren aus <span class="math notranslate nohighlight">\( K_1 \)</span> ist, also beispielsweise <span class="math notranslate nohighlight">\(	( 1, 0 , 0 , 0 , 0)^T \)</span>.
Wir notieren diesen Vektor in ein Schema wie folgt:\[.5cm]</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p><span class="math notranslate nohighlight">\(\begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p></p></td>
</tr>
</tbody>
</table>
<p><strong>2. Schritt: Hauptvektoren der Stufe <span class="math notranslate nohighlight">\(1\)</span></strong></p>
<p>Wir berechnen zunächst <span class="math notranslate nohighlight">\( G_2 \cdot ( 1, 0 , 0 , 0 , 0)^T  = (1,0,-1,0,0)^T \)</span> und tragen diesen Vektor in einer neuen Zeile unten in das Schema ein.
Wir berechnen</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
s_1 \, = \, \Delta_1 - \Delta_2 \, = \, 2 - 1 \, = \, 1.
\end{equation*}\]</div>
<p>Dies bedeutet, dass wir noch einen weiteren Hauptvektor der Stufe <span class="math notranslate nohighlight">\(1\)</span> aus <span class="math notranslate nohighlight">\(K_1\)</span> zu unserem Schema hinzufügen müssen.
Hierzu wählen wir den Vektor <span class="math notranslate nohighlight">\( (0,0,0,0,1)^T \)</span>.
Dies ist konsistent zu der Beobachtung, dass das Schema nun <span class="math notranslate nohighlight">\(r_2 = 3\)</span> Vektoren enthält.</p>
<p>Das finale Schema für den <strong>zweiten Jordanblock</strong> sieht entsprechend so aus:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p><span class="math notranslate nohighlight">\( \begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix} \)</span></p></th>
<th class="text-align:left head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span class="math notranslate nohighlight">\( \begin{pmatrix} 1 \\ 0 \\ -1 \\ 0 \\ 0 \end{pmatrix} \)</span></p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(\begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 1 \end{pmatrix}\)</span></p></td>
</tr>
</tbody>
</table>
<p>Die Basis <span class="math notranslate nohighlight">\( B_2 \)</span> für den Hauptraum <span class="math notranslate nohighlight">\(\Hau(A; 4)\)</span> von <span class="math notranslate nohighlight">\(A\)</span> zum Eigenwert <span class="math notranslate nohighlight">\(\lambda_2 = 4\)</span> ergibt sich entsprechend durch Ablesen des Schemas <em>von unten nach oben, von links nach rechts</em>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
B_2 \ \coloneqq \ 
    \begin{pmatrix}
        1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ -1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1
    \end{pmatrix}.
\end{equation*}\]</div>
<p>Wir fügen abschließend die beiden Basen <span class="math notranslate nohighlight">\(B_1\)</span> und <span class="math notranslate nohighlight">\(B_2\)</span> der zwei Haupträume zu einer Basis <span class="math notranslate nohighlight">\(B\)</span> von <span class="math notranslate nohighlight">\(V\)</span> zusammen und schreiben die Basisvektoren von <span class="math notranslate nohighlight">\(B\)</span> als Spalten der Transformationsmatrix</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
S^{-1} \ \coloneqq \ 
    \begin{pmatrix}
        0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\ 
        1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\ 
        0 &amp; 0 &amp; -1 &amp; 0 &amp; 0 \\ 
        -1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\ 
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
    \end{pmatrix},
    \quad
    S \ \coloneqq \ 
    \begin{pmatrix}
        0 &amp; \frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\ 
        0 &amp; -\frac{1}{2} &amp; 0 &amp; -\frac{1}{2} &amp; 0 \\ 
        0 &amp; 0 &amp; -1 &amp; 0 &amp; 0 \\ 
        1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\ 
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
    \end{pmatrix}.
\end{equation*}\]</div>
<p>Entsprechend erhalten wir</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
    \begin{pmatrix}
        1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
        0 &amp; 0 &amp; 4 &amp; 1 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 \\
        0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 \\
    \end{pmatrix}
\end{equation*}\]</div>
<p>Wir können uns während der Bestimmung einer Jordanschen Normalform auch mittels der Jordanketten die passende Jordannormalform schon überlegen.
Zu <span class="math notranslate nohighlight">\(\Hau(A;1)\)</span> gehört nur ein Jordankästchen der Dimension <span class="math notranslate nohighlight">\( 2 \times 2 \)</span> (eine Jordankette der Länge <span class="math notranslate nohighlight">\(2\)</span>).
Zu <span class="math notranslate nohighlight">\(\Hau(A;4)\)</span>  gehört ein Jordankästchen der Dimension <span class="math notranslate nohighlight">\( 2 \times 2 \)</span> (eine Jordankette der Länge <span class="math notranslate nohighlight">\(2\)</span>) und eine Jordankästchen der Dimension <span class="math notranslate nohighlight">\( 1 \times 1 \)</span> (eine Jordankette der Länge <span class="math notranslate nohighlight">\(1\)</span>).</p>
</div>
</div><p>Glücklicherweise  existieren Algorithmen, die die obigen Berechnungen automatisiert in einem Computer durchführen und dabei mögliche Rechenfehler vermeiden und uns somit viel Zeit sparen.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./eigenwerte"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="triag.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">1.5. </span>Trigonalisierbarkeit</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="../vektoraeume/vektoraeume.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">2. </span>Euklidische und unitäre Vektorräume</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>